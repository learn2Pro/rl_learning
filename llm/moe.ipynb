{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "722875fd-6ce1-4ffb-ad47-658282a0fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c49a91-38ef-4e21-9c0d-3836fed8e0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3119, 1.2256],\n",
      "        [1.2041, 0.8192]]) tensor([[2, 5],\n",
      "        [7, 1]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5215, 0.4785],\n",
       "        [0.5950, 0.4050]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,8)\n",
    "\n",
    "probs, indices = torch.topk(x, 2, dim=-1)\n",
    "print(probs, indices)\n",
    "\n",
    "F.softmax(probs, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bebf57e5-75ed-49e3-a885-943ed09c9ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 5],\n",
      "        [7, 1]])\n",
      "tensor([[[0, 0, 1, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 1, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0, 0, 1],\n",
      "         [0, 1, 0, 0, 0, 0, 0, 0]]])\n",
      "tensor([[[0, 0],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[0, 0],\n",
      "         [0, 1]],\n",
      "\n",
      "        [[1, 0],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[0, 0],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[0, 0],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[0, 0],\n",
      "         [1, 0]],\n",
      "\n",
      "        [[0, 0],\n",
      "         [0, 0]],\n",
      "\n",
      "        [[0, 1],\n",
      "         [0, 0]]])\n"
     ]
    }
   ],
   "source": [
    "print(indices)\n",
    "mask = F.one_hot(indices, num_classes=8)\n",
    "print(mask)\n",
    "mask = mask.permute(2, 1, 0)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5d8cc1f-0a8a-4c08-a5f1-8e6c1ea5784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0],\n",
      "        [0, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f302175-40bb-481f-a0d1-0945b784fb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1]) tensor([0, 0])\n"
     ]
    }
   ],
   "source": [
    "idx,token_idx = torch.where(torch.Tensor([[1,0],[1,0]]))\n",
    "print(idx, token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8199a4b5-b827-4470-816c-e0fb723f4dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3119, 1.2256])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[token_idx, idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db1ce071-e5b2-463b-96fc-46f82757ad3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 5])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.randn(2, 4, 5) * torch.randn(2, 4, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74d5862f-bc0d-4881-9617-27186f48ac02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Expert(nn.Module):\n",
    "    def __init__(self, f_in, f_out):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(f_in, f_out),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "exp = Expert(10,20)\n",
    "exp(torch.randn(2,10)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7da28d9-6ed9-4efd-8144-91c14bd0448d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 20])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BasicMOE(nn.Module):\n",
    "    def __init__(self, f_in, f_out, n_expert):\n",
    "        super().__init__()\n",
    "        self.nets = nn.ModuleList(\n",
    "            [Expert(f_in, f_out) for _ in range(n_expert)]\n",
    "        )\n",
    "        # gate\n",
    "        self.gate = nn.Linear(f_in, n_expert)\n",
    "\n",
    "    def forward(self, x):\n",
    "        weight = self.gate(x) # (B, n_expert)\n",
    "        outputs = torch.cat([exp(x).unsqueeze(1) for exp in self.nets], dim=1) # (B, n_expert, f_out)\n",
    "        x = weight.unsqueeze(1) @ outputs # (B, 1, f_out)\n",
    "        return x.squeeze(1)\n",
    "\n",
    "\n",
    "moe = BasicMOE(10,20,8)\n",
    "moe(torch.randn(2,10)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22211892-5032-497d-bb2c-eedd8a97bd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4]) torch.Size([8, 2]) torch.Size([4, 2, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0326e-02,  1.9251e-01, -6.2082e-02,  1.8105e-01,  4.0711e-04,\n",
       "           1.7474e-01,  1.7426e-01, -1.6486e-01],\n",
       "         [ 1.1799e-01, -5.3165e-02,  4.2430e-01, -8.8925e-02, -8.0590e-02,\n",
       "           6.2828e-01,  2.1644e-01, -1.6243e-01],\n",
       "         [ 1.5192e-01, -7.0823e-02, -8.2092e-02, -1.3237e-01,  2.4077e-01,\n",
       "          -1.1497e-01,  5.0428e-03, -1.6479e-01],\n",
       "         [-7.3801e-02,  1.8053e-01,  4.0537e-02, -3.7610e-02,  1.6313e-01,\n",
       "           3.0721e-01,  7.9455e-01,  1.4426e-01]],\n",
       "\n",
       "        [[ 4.1279e-01, -1.1055e-01,  2.3830e-01, -1.2703e-01,  8.6327e-03,\n",
       "          -4.3897e-02,  1.5085e-01, -1.0080e-01],\n",
       "         [-1.0584e-01,  6.0744e-01, -1.6124e-01, -6.6115e-02,  1.6061e-01,\n",
       "           1.8657e-01, -1.6364e-01,  3.7994e-01],\n",
       "         [-7.7603e-03,  6.1990e-01, -1.0862e-01,  1.3450e-01,  1.7599e-01,\n",
       "           1.7986e-01,  5.4610e-01, -1.3224e-01],\n",
       "         [ 5.1953e-02,  1.1769e+00, -4.3976e-02,  5.6574e-01,  7.1521e-01,\n",
       "           6.2427e-02, -4.6838e-02,  4.3063e-01]]], device='cuda:0',\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "@dataclass\n",
    "class MOEConfig:\n",
    "    hidden_dim: int\n",
    "    n_expert: int\n",
    "    top_k: int\n",
    "    n_share_expert: int = 2\n",
    "\n",
    "class MOERouter(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Linear(config.hidden_dim, config.n_expert)\n",
    "        self.n_expert = config.n_expert\n",
    "        self.top_k = config.top_k\n",
    "\n",
    "    def forward(self, x):\n",
    "        # gate logits\n",
    "        router_logits = self.gate(x) # (B*ns, n_expert)\n",
    "\n",
    "        # top k\n",
    "        # weights (B*ns, top_k)\n",
    "        weights, indices = torch.topk(router_logits, self.top_k, dim=-1)\n",
    "\n",
    "        # norm\n",
    "        weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "        # expert mask (B*ns, top_k, n_expert)\n",
    "        expert_mask = F.one_hot(indices, num_classes=self.n_expert)\n",
    "        # permute (n_expert, top_k, B*ns)\n",
    "        expert_mask = expert_mask.permute(2, 1, 0)\n",
    "\n",
    "        return router_logits, weights, indices, expert_mask\n",
    "        \n",
    "    \n",
    "class SparseMOE(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.experts = nn.ModuleList(\n",
    "            [Expert(config.hidden_dim, config.hidden_dim) for _ in range(config.n_expert)]\n",
    "        )\n",
    "        self.router = MOERouter(config)\n",
    "        self.hidden_dim = config.hidden_dim\n",
    "        self.n_expert = config.n_expert\n",
    "        self.top_k = config.top_k\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, ns, nh = x.size()\n",
    "        # (B*ns, nh)\n",
    "        hs = x.view(-1, nh)\n",
    "\n",
    "        # router select\n",
    "        router_logits, weights, indices, expert_mask = self.router(hs)\n",
    "\n",
    "        print(router_logits.shape, weights.shape, expert_mask.shape)\n",
    "\n",
    "        # \n",
    "        final_hs = torch.zeros((B*ns, nh), dtype=x.dtype).to(device)\n",
    "\n",
    "        for idx in range(self.n_expert):\n",
    "            expert_layer = self.experts[idx]\n",
    "            # (n_expert, top_k, B)\n",
    "            idx, token_idx = torch.where(expert_mask[idx])\n",
    "            # (len(token_idx), nh)\n",
    "            current_state = hs.unsqueeze(0)[:, token_idx, :].reshape(-1, nh)\n",
    "            # current_hs * weights\n",
    "            # weights (B*ns, top_k) -> (len(token_idx)*len(idx), 1)\n",
    "            router_weights = weights[token_idx, idx].unsqueeze(-1)\n",
    "            current_hs = expert_layer(current_state) \n",
    "            # (len(token_idx, nh) * (len(token_idx), 1)\n",
    "            current_hs =  current_hs * router_weights\n",
    "            # add \n",
    "            final_hs[token_idx]+=current_hs\n",
    "        final_hs = final_hs.view(B, ns, nh)\n",
    "        return final_hs, router_logits\n",
    "\n",
    "x = torch.randn(2, 4, 8).to(device)\n",
    "config = MOEConfig(8, 4, 2)\n",
    "moe = SparseMOE(config).to(device)\n",
    "hs, logits = moe(x)\n",
    "hs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d15481d-eb14-406d-8444-e363474ba6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([torch.randn(2,3), torch.randn(2,3)], dim=0).sum(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78ee910-b868-4de3-9fce-6060f5cbf959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
