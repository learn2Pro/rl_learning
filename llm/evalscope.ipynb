{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a491ba0e-b7d7-463f-abc2-389dd772340e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 15:05:59,315 - evalscope - INFO - Args: Task config is provided with dictionary type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /home/samtang/.cache/modelscope/hub/models/LLM-Research/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 15:05:59,664 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "2025-04-03 15:06:00,028 - modelscope - INFO - Got 12 files, start to download ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6adc41b975492483b3396a373e9c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 12 items:   0%|          | 0.00/12.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de8f12b65d5843aa862ab7e8121e1c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [chat_template.json]:   0%|          | 0.00/1.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2e65a825a94c3f8f7ebda0916dc8e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [generation_config.json]:   0%|          | 0.00/215 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec125ed827524718835aeb982018933e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [configuration.json]:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f535cc59b11c4477af49de86eede7dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [config.json]:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83a2c12a2024383a363e64a18a6e6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [preprocessor_config.json]:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbdc3327edca4285bab6a95bcf3a6164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [README.md]:   0%|          | 0.00/24.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1009489f564f498da1e465de59274a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [added_tokens.json]:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539b79a3bdf74739a5927bc36f77700e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [processor_config.json]:   0%|          | 0.00/70.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cea1cfb7fca4e8eb001e455d7b2c3c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [special_tokens_map.json]:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef8aee7305e41c596aa8b9565db57b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [tokenizer.json]:   0%|          | 0.00/31.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f06b2fb03cf40b494d69e78ffd21c0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [tokenizer.model]:   0%|          | 0.00/4.47M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206bc3aee7fd4c4cbfd73b4dba8435f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [tokenizer_config.json]:   0%|          | 0.00/1.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 15:06:03,953 - modelscope - INFO - Download model 'LLM-Research/gemma-3-4b-it' successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /home/samtang/.cache/modelscope/hub/models/LLM-Research/gemma-3-4b-it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-03 15:06:04,949 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "2025-04-03 15:06:05,457 - modelscope - INFO - Got 3 files, start to download ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd83a6c2a1844c7aa70a0020298b5fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 3 items:   0%|          | 0.00/3.00 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7ececaa86d4a79b6d78607c8b9ff0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [model-00002-of-00002.safetensors]:   0%|          | 0.00/3.39G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17476f8df7974ca4a37cd498615562fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [model-00001-of-00002.safetensors]:   0%|          | 0.00/4.62G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd5a9baed86d457b8d5f39b4c98a5c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [model.safetensors.index.json]:   0%|          | 0.00/88.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from evalscope import TaskConfig, run_task\n",
    "import os, httpx\n",
    "os.environ['all_proxy'] = ''\n",
    "\n",
    "# task_config = TaskConfig(\n",
    "#     api_url='http://127.0.0.1:8000/v1/chat/completions',  # Inference service address\n",
    "#     model='gpt2',  # Model name (must match the deployed model name)\n",
    "#     eval_type='service',  # Evaluation type, SERVICE indicates evaluating the inference service\n",
    "#     datasets=['math_500'],  # Dataset name\n",
    "#     dataset_args={'math_500': {'few_shot_num': 0, 'subset_list': ['Level 1', 'Level 2', 'Level 3', 'Level 4', 'Level 5']}},  # Dataset parameters\n",
    "#     eval_batch_size=32,  # Number of concurrent requests\n",
    "#     generation_config={\n",
    "#         'max_tokens': 20000,  # Maximum number of tokens to generate; suggested to set a high value to avoid truncation\n",
    "#         'temperature': 0.6,  # Sampling temperature (recommended value from deepseek)\n",
    "#         'top_p': 0.95,  # Top-p sampling (recommended value from deepseek)\n",
    "#         'n': 1,  # Number of responses generated for each request\n",
    "#     },\n",
    "# )\n",
    "\n",
    "task_config = {\n",
    "    'model': 'LLM-Research/gemma-3-4b-it',\n",
    "    'datasets': ['gsm8k', 'arc'],\n",
    "    'limit': 5\n",
    "}\n",
    "\n",
    "run_task(task_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acdca1cb-2464-4feb-93b9-9af345a6715e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'opencompass'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mevalscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopencompass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenCompassBackendManager\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# list datasets\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mOpenCompassBackendManager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/evalscope/backend/opencompass/backend_manager.py:111\u001b[0m, in \u001b[0;36mOpenCompassBackendManager.list_datasets\u001b[0;34m(return_details)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlist_datasets\u001b[39m(return_details: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdataclasses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataclass\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopencompass\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrun\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config_from_arg\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTempArgs\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m         config: \u001b[38;5;28mstr\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'opencompass'"
     ]
    }
   ],
   "source": [
    "from evalscope.backend.opencompass import OpenCompassBackendManager\n",
    "# list datasets\n",
    "OpenCompassBackendManager.list_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6065a8a-66ac-476b-afa8-a7ffb76cd80c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
