{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a46ecc7-1c88-47c9-b86a-3b36c2a2b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class GPTConfig:\n",
    "    n_block: int\n",
    "    n_layer: int\n",
    "    n_head: int\n",
    "    n_embed: int\n",
    "    n_vocab: int = 50257\n",
    "    n_kv_head: int = 2\n",
    "    model_type: str = 'buddygpt'\n",
    "    pad_token_id=None,\n",
    "    bos_token_id=None,\n",
    "    eos_token_id=50256,\n",
    "    keys_to_ignore_at_inference = [\"past_key_values\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12cbc23b-44c6-4e16-bac7-3e663ce28cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # rope\n",
    "# def precompute_freqs_cis(dim, max_seq_len=2048, theta=10000.0):\n",
    "#     freqs = theta ** -(torch.arange(0, dim, 2)[:dim//2].float() / dim)\n",
    "#     t = torch.arange(max_seq_len)\n",
    "#     freqs = torch.outer(t, freqs) # m * \\theta\n",
    "#     # freqs = t * freqs\n",
    "#     freqs = torch.polar(torch.ones_like(freqs), freqs) # cos(m * \\theta) + jsin(m * \\theta)\n",
    "#     return \n",
    "\n",
    "# # 2. 为广播 reshape freqs\n",
    "# def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "#     if freqs_cis.shape[0] > x.shape[1]:\n",
    "#         freqs_cis = freqs_cis[:x.shape[1]]\n",
    "#     assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "#     shape = [1 if i != 1 and i != x.ndim - 1 else x.shape[i] for i in range(x.ndim)]\n",
    "#     return freqs_cis.view(*shape).to(x.device)\n",
    "\n",
    "# def apply_rotary_emb(q, k, freqs):\n",
    "#     xq = torch.view_as_complex(q.view(*q.shape[:-1], -1, 2)) # batch, seq_len, n_head, dim//2\n",
    "#     xk = torch.view_as_complex(k.view(*k.shape[:-1], -1, 2)) # batch, seq_len, n_head, dim//2\n",
    "    \n",
    "#     freqs_cis = reshape_for_broadcast(freqs, xq) # freqs_cis.shape = (1,seq_len,1,dim//2)\n",
    "\n",
    "#     xq_out = torch.view_as_real(xq * freqs_cis).flatten(3) # batch, seq_len, n_head, dim\n",
    "#     xk_out = torch.view_as_real(xk * freqs_cis).flatten(3) # batch, seq_len, n_head, dim\n",
    "\n",
    "#     return xq_out.type_as(q), xk_out.type_as(k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288d1a06-9265-47b8-9f6e-1a242e69d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rope = precompute_freqs_cis(dim=64)\n",
    "# q = torch.randn(2, 4, 12, 64)  # B=2, H=4, T=12, D=64\n",
    "# k = torch.randn(2, 4, 12, 64)\n",
    "# xq, xk = apply_rotary_emb(q, k, rope)\n",
    "# xq.shape, xk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202b0a3a-457e-46d2-b925-3a94c9f03f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "086267e4-eb88-4527-840b-b654b29f270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotaryEmbedding(nn.Module):\n",
    "    def __precompute_freqs_cis(self, dim, max_seq_len, theta):\n",
    "        assert dim%2 == 0\n",
    "        freqs = theta ** -(torch.arange(0, dim ,2).float() / dim)\n",
    "        t = torch.arange(max_seq_len)\n",
    "        freqs = torch.outer(t, freqs) # (seq_len, dim/2)\n",
    "        freqs = torch.polar(torch.ones_like(freqs), freqs) # cos(m*\\theta) + jsin(m*\\theat)\n",
    "        return freqs\n",
    "        \n",
    "    def __init__(self, dim, max_seq_len=2048, theta=10000.0):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.freqs = self.__precompute_freqs_cis(dim, max_seq_len, theta)\n",
    "\n",
    "    def apply_rotary_emb(self, q, k=None):\n",
    "        seq_len, dim = q.size(1), q.size(-1) # batch, n_head, seq_len, n_embed\n",
    "        freqs_cis = self.freqs[None, :seq_len, None, :dim//2].contiguous()\n",
    "        xq = torch.view_as_complex(q.view(*q.shape[:-1], -1, 2))\n",
    "        xq_out = torch.view_as_real(xq * freqs_cis).flatten(3)\n",
    "        if k is not None:\n",
    "            xk = torch.view_as_complex(k.view(*k.shape[:-1], -1, 2))\n",
    "            xk_out = torch.view_as_real(xk * freqs_cis).flatten(3)\n",
    "            return xq_out, xk_out\n",
    "        else:\n",
    "            return xq_out\n",
    "                                   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92079af8-66a8-420e-81b8-3402fee1ac35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 12, 4, 64]), torch.Size([2, 12, 4, 64]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rope = RotaryEmbedding(dim=64)\n",
    "q = torch.randn(2, 12, 4, 64) # batch, n_head, seq_len, n_embed\n",
    "k = torch.randn(2, 12, 4, 64)\n",
    "q1,k1 = rope.apply_rotary_emb(q, k)\n",
    "q1.shape,k1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ec4e4e7-993d-4a8c-8854-84e9612cf3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GQA(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.n_head = config.n_head\n",
    "        self.n_kv_head = config.n_kv_head\n",
    "        self.n_embed = config.n_embed\n",
    "        self.head_dim = self.n_embed // self.n_head\n",
    "        self.kv_head_dim = self.head_dim * self.n_kv_head\n",
    "        self.repeat_factor = self.n_head // self.n_kv_head\n",
    "        self.q_proj = nn.Linear(self.n_embed, self.n_embed)\n",
    "        self.k_proj = nn.Linear(self.n_embed, self.kv_head_dim)\n",
    "        self.v_proj = nn.Linear(self.n_embed, self.kv_head_dim)\n",
    "        self.out_proj = nn.Linear(self.n_embed, self.n_embed)\n",
    "        self.rope = RotaryEmbedding(self.n_embed)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(config.n_block, config.n_block)).view(1,1,config.n_block, config.n_block))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, _ = x.shape\n",
    "        q = self.q_proj(x).view(B, T, self.n_head, -1) # B, T, n_head, n_embed\n",
    "        k = self.k_proj(x).view(B, T, self.n_kv_head, -1) # B, T, n_kv_head, n_embed\n",
    "        v = self.v_proj(x).view(B, T, self.n_kv_head, -1) # B, T, n_kv_head, n_embed\n",
    "\n",
    "        xq, xk = self.rope.apply_rotary_emb(q), self.rope.apply_rotary_emb(k)\n",
    "\n",
    "        xq = xq.transpose(1, 2) # B, n_head, T, n_embed\n",
    "        xk = xk.transpose(1, 2) # B, n_kv_head, T, n_embed\n",
    "        xv = v.transpose(1, 2) # B, n_kv_head, T, n_embed\n",
    "\n",
    "        xk = xk.repeat_interleave(self.repeat_factor, dim=1) # B, n_head, T, n_embed\n",
    "        xv = xv.repeat_interleave(self.repeat_factor, dim=1) # B, n_head, T, n_embed\n",
    "\n",
    "        if FLASH:\n",
    "            o_attn = F.scaled_dot_product_attention(q, k, v, is_causal=True)\n",
    "        else:\n",
    "            qk = torch.matmul(xq, xk.transpose(-2, -1))\n",
    "            qk = qk.masked_fill(self.tril[:,:,:T,:T]==0, float('-inf'))\n",
    "            qk = F.softmax(qk, dim=-1) * (self.n_embed ** -0.5)\n",
    "            o_attn = qk @ xv # B, n_head, T, n_embed\n",
    "        o_attn = o_attn.transpose(1, 2).contiguous().view(B, T, -1)\n",
    "        return self.out_proj(o_attn)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdd63794-ea67-4585-8d66-a3bdb0bb8444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FLASH=1\n",
    "config = GPTConfig(n_block=512, n_layer=2, n_head=8, n_embed=64, n_kv_head=2)\n",
    "gqa = GQA(config)  \n",
    "x = torch.randn(2, 12, 64) \n",
    "gqa(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "195dde58-21e7-4a10-9809-c9cf2e0ce4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 12, 32]), torch.Size([2, 12, 32]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0, x1 = x.chunk(2, dim=-1)\n",
    "x0.shape,x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6820057-38d3-454c-bfb9-577a858b357f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(F.silu(x0) * x1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c5a8e5-a8c0-4263-91d5-cd1bc840e31b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
