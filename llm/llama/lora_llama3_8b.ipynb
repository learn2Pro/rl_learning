{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: trl in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (0.12.2)\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from trl) (1.1.1)\n",
      "Requirement already satisfied: datasets>=2.21.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from trl) (3.1.0)\n",
      "Requirement already satisfied: rich in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from trl) (13.9.4)\n",
      "Requirement already satisfied: transformers<4.47.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from trl) (4.46.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (0.26.3)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (24.2)\n",
      "Requirement already satisfied: psutil in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (0.4.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from accelerate>=0.34.0->trl) (2.5.1)\n",
      "Requirement already satisfied: filelock in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.21.0->trl) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from datasets>=2.21.0->trl) (3.11.10)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from transformers<4.47.0->trl) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from transformers<4.47.0->trl) (0.20.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from rich->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from rich->trl) (2.18.0)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from rich->trl) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from aiohttp->datasets>=2.21.0->trl) (1.18.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=2.21.0->trl) (2024.8.30)\n",
      "Requirement already satisfied: networkx in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate>=0.34.0->trl) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from pandas->datasets>=2.21.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from pandas->datasets>=2.21.0->trl) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from pandas->datasets>=2.21.0->trl) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.21.0->trl) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate>=0.34.0->trl) (3.0.2)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: bitsandbytes in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (0.45.0)\n",
      "Requirement already satisfied: torch in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from bitsandbytes) (2.5.1)\n",
      "Requirement already satisfied: numpy in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from bitsandbytes) (2.1.3)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: filelock in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch->bitsandbytes) (3.16.1)\n",
      "Requirement already satisfied: networkx in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch->bitsandbytes) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch->bitsandbytes) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch->bitsandbytes) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch->bitsandbytes) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch->bitsandbytes) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch->bitsandbytes) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch->bitsandbytes) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch->bitsandbytes) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch->bitsandbytes) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from torch->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: seaborn in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: scikit-learn in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from seaborn) (3.9.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade trl\n",
    "!pip install --upgrade bitsandbytes\n",
    "!pip install seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['http_proxy'] = 'http://127.0.0.1:7890'\n",
    "os.environ['https_proxy'] = 'http://127.0.0.1:7890'\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.mlexpert.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbanner.2336875a.png&w=3840&q=75\" width=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='https://www.mlexpert.io/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fbanner.2336875a.png&w=3840&q=75', width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import Dict, List\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset, load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline,\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    TaskType,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from trl import DataCollatorForCompletionOnlyLM, SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token = \"<|pad|>\"\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "new_model = \"Llama-3-8B-Instruct-Finance-RAG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "login(token='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', add_to_git_credential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_quant_type=\"nf4\", \n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "# tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\\nYou are a helpful assistant<|im_end|>\\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\\n' }}{% endif %}\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = 'Qwen/Qwen2-0.5B'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=True)\n",
    "tokenizer.chat_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system<|end_header_id|>\n",
      "You are a helpful assistant<|im_end|>\n",
      "' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|end_header_id|><|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant<|end_header_id|>\n",
      "' }}{% endif %}\n",
      "\n",
      "{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system<|end_header_id|>\n",
      "You are a helpful assistant<|im_end|>\n",
      "' }}{% endif %}{{'<|im_start|>' + message['role'] + '<|end_header_id|>\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant<|end_header_id|>\n",
      "' }}{% endif %}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.chat_template)\n",
    "tokenizer.chat_template = \"{% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system<|end_header_id|>\\nYou are a helpful assistant<|im_end|>\\n' }}{% endif %}{{'<|im_start|>' + message['role'] + '<|end_header_id|>\\n' + message['content'] + '<|im_end|>' + '\\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant<|end_header_id|>\\n' }}{% endif %}\"\n",
    "print()\n",
    "\n",
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|startoftext|>',\n",
       " 'eos_token': '<|endoftext|>',\n",
       " 'pad_token': '<|endoftext|>',\n",
       " 'additional_special_tokens': ['<|im_start|>', '<|im_end|>']}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bos_token': '<|startoftext|>',\n",
       " 'eos_token': '<|endoftext|>',\n",
       " 'pad_token': '<|endoftext|>',\n",
       " 'additional_special_tokens': ['<|im_start|>', '<|im_end|>']}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({'bos_token':'<|startoftext|>'})\n",
    "tokenizer.special_tokens_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<|endoftext|>', 'right')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token, tokenizer.padding_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear4bit(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear4bit(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear4bit(in_features=896, out_features=896, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear4bit(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.added_tokens_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Embedding(151936, 896), 151643, 151647)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.embed_tokens, tokenizer.vocab_size, len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(151648, 896)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16032.125, 16033.0)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128257/8, 128264/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2Config {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"_name_or_path\": \"Qwen/Qwen2-0.5B\",\n",
       "  \"architectures\": [\n",
       "    \"Qwen2ForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 151643,\n",
       "  \"eos_token_id\": 151643,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 896,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 4864,\n",
       "  \"max_position_embeddings\": 131072,\n",
       "  \"max_window_layers\": 24,\n",
       "  \"model_type\": \"qwen2\",\n",
       "  \"num_attention_heads\": 14,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"num_key_value_heads\": 2,\n",
       "  \"quantization_config\": {\n",
       "    \"_load_in_4bit\": true,\n",
       "    \"_load_in_8bit\": false,\n",
       "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
       "    \"bnb_4bit_quant_storage\": \"uint8\",\n",
       "    \"bnb_4bit_quant_type\": \"nf4\",\n",
       "    \"bnb_4bit_use_double_quant\": false,\n",
       "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
       "    \"llm_int8_has_fp16_weight\": false,\n",
       "    \"llm_int8_skip_modules\": null,\n",
       "    \"llm_int8_threshold\": 6.0,\n",
       "    \"load_in_4bit\": true,\n",
       "    \"load_in_8bit\": false,\n",
       "    \"quant_method\": \"bitsandbytes\"\n",
       "  },\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 1000000.0,\n",
       "  \"sliding_window\": null,\n",
       "  \"tie_word_embeddings\": true,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.46.3\",\n",
       "  \"use_cache\": true,\n",
       "  \"use_sliding_window\": false,\n",
       "  \"vocab_size\": 151648\n",
       "}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|startoftext|> 151646\n",
      "<|endoftext|> 151643\n",
      "<|endoftext|> 151643\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.bos_token, tokenizer.bos_token_id)\n",
    "print(tokenizer.eos_token, tokenizer.eos_token_id)\n",
    "print(tokenizer.pad_token, tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset (数据集就代表着任务)\n",
    "\n",
    "- RAG dataset with QA and context;\n",
    "    - Question + context => user query;\n",
    "- Answer => assistant response;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"virattt/financial-qa-10K\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'context', 'ticker', 'filing'],\n",
       "        num_rows: 7000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': ['What area did NVIDIA initially focus on before expanding to other computationally intensive fields?'],\n",
       " 'answer': ['NVIDIA initially focused on PC graphics.'],\n",
       " 'context': ['Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields.'],\n",
       " 'ticker': ['NVDA'],\n",
       " 'filing': ['2023_10K']}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question', 'answer', 'context', 'ticker', 'filing']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'context'],\n",
       "        num_rows: 7000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process(row):\n",
    "    return {\n",
    "        \"question\": row[\"question\"],\n",
    "        \"context\": row[\"context\"],\n",
    "        \"answer\": row[\"answer\"]\n",
    "    }\n",
    "new_dataset = dataset.map(process, num_proc=8, \n",
    "                          remove_columns=dataset[\"train\"].column_names)\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What area did NVIDIA initially focus on before...</td>\n",
       "      <td>NVIDIA initially focused on PC graphics.</td>\n",
       "      <td>Since our original focus on PC graphics, we ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are some of the recent applications of GP...</td>\n",
       "      <td>Recent applications of GPU-powered deep learni...</td>\n",
       "      <td>Some of the most recent applications of GPU-po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What significant invention did NVIDIA create i...</td>\n",
       "      <td>NVIDIA invented the GPU in 1999.</td>\n",
       "      <td>Our invention of the GPU in 1999 defined moder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does NVIDIA's platform strategy contribute...</td>\n",
       "      <td>NVIDIA's platform strategy brings together har...</td>\n",
       "      <td>NVIDIA has a platform strategy, bringing toget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What does NVIDIA's CUDA programming model enable?</td>\n",
       "      <td>NVIDIA's CUDA programming model opened the par...</td>\n",
       "      <td>With our introduction of the CUDA programming ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What area did NVIDIA initially focus on before...   \n",
       "1  What are some of the recent applications of GP...   \n",
       "2  What significant invention did NVIDIA create i...   \n",
       "3  How does NVIDIA's platform strategy contribute...   \n",
       "4  What does NVIDIA's CUDA programming model enable?   \n",
       "\n",
       "                                              answer  \\\n",
       "0           NVIDIA initially focused on PC graphics.   \n",
       "1  Recent applications of GPU-powered deep learni...   \n",
       "2                   NVIDIA invented the GPU in 1999.   \n",
       "3  NVIDIA's platform strategy brings together har...   \n",
       "4  NVIDIA's CUDA programming model opened the par...   \n",
       "\n",
       "                                             context  \n",
       "0  Since our original focus on PC graphics, we ha...  \n",
       "1  Some of the most recent applications of GPU-po...  \n",
       "2  Our invention of the GPU in 1999 defined moder...  \n",
       "3  NVIDIA has a platform strategy, bringing toget...  \n",
       "4  With our introduction of the CUDA programming ...  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = new_dataset['train'].to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question  answer  context\n",
       "False     False   False      7000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## to chat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question    What area did NVIDIA initially focus on before...\n",
       "answer               NVIDIA initially focused on PC graphics.\n",
       "context     Since our original focus on PC graphics, we ha...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = df.iloc[0]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "What area did NVIDIA initially focus on before expanding to other computationally intensive fields?\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields.\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textwrap import dedent\n",
    "print(dedent(\n",
    "    f\"\"\"\n",
    "{row[\"question\"]}\n",
    "\n",
    "Information:\n",
    "\n",
    "```\n",
    "{row[\"context\"]}\n",
    "```\n",
    "\"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_example(row: dict):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "    {row[\"question\"]}\n",
    "\n",
    "    Information:\n",
    "\n",
    "    ```\n",
    "    {row[\"context\"]}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Use only the information to answer the question\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": row[\"answer\"]},\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df.apply(format_example, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system<|end_header_id|>\n",
      "Use only the information to answer the question<|im_end|>\n",
      "<|im_start|>user<|end_header_id|>\n",
      "\n",
      "What area did NVIDIA initially focus on before expanding to other computationally intensive fields?\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "Since our original focus on PC graphics, we have expanded to several other large and important computationally intensive fields.\n",
      "```\n",
      "<|im_end|>\n",
      "<|im_start|>assistant<|end_header_id|>\n",
      "NVIDIA initially focused on PC graphics.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(row: Dict) -> int:\n",
    "    return len(\n",
    "        tokenizer(\n",
    "            row[\"text\"],\n",
    "            add_special_tokens=True,\n",
    "            return_attention_mask=False,\n",
    "        )[\"input_ids\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"token_count\"] = df.apply(count_tokens, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>context</th>\n",
       "      <th>text</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What area did NVIDIA initially focus on before...</td>\n",
       "      <td>NVIDIA initially focused on PC graphics.</td>\n",
       "      <td>Since our original focus on PC graphics, we ha...</td>\n",
       "      <td>&lt;|im_start|&gt;system&lt;|end_header_id|&gt;\\nUse only ...</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are some of the recent applications of GP...</td>\n",
       "      <td>Recent applications of GPU-powered deep learni...</td>\n",
       "      <td>Some of the most recent applications of GPU-po...</td>\n",
       "      <td>&lt;|im_start|&gt;system&lt;|end_header_id|&gt;\\nUse only ...</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What significant invention did NVIDIA create i...</td>\n",
       "      <td>NVIDIA invented the GPU in 1999.</td>\n",
       "      <td>Our invention of the GPU in 1999 defined moder...</td>\n",
       "      <td>&lt;|im_start|&gt;system&lt;|end_header_id|&gt;\\nUse only ...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does NVIDIA's platform strategy contribute...</td>\n",
       "      <td>NVIDIA's platform strategy brings together har...</td>\n",
       "      <td>NVIDIA has a platform strategy, bringing toget...</td>\n",
       "      <td>&lt;|im_start|&gt;system&lt;|end_header_id|&gt;\\nUse only ...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What does NVIDIA's CUDA programming model enable?</td>\n",
       "      <td>NVIDIA's CUDA programming model opened the par...</td>\n",
       "      <td>With our introduction of the CUDA programming ...</td>\n",
       "      <td>&lt;|im_start|&gt;system&lt;|end_header_id|&gt;\\nUse only ...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What area did NVIDIA initially focus on before...   \n",
       "1  What are some of the recent applications of GP...   \n",
       "2  What significant invention did NVIDIA create i...   \n",
       "3  How does NVIDIA's platform strategy contribute...   \n",
       "4  What does NVIDIA's CUDA programming model enable?   \n",
       "\n",
       "                                              answer  \\\n",
       "0           NVIDIA initially focused on PC graphics.   \n",
       "1  Recent applications of GPU-powered deep learni...   \n",
       "2                   NVIDIA invented the GPU in 1999.   \n",
       "3  NVIDIA's platform strategy brings together har...   \n",
       "4  NVIDIA's CUDA programming model opened the par...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Since our original focus on PC graphics, we ha...   \n",
       "1  Some of the most recent applications of GPU-po...   \n",
       "2  Our invention of the GPU in 1999 defined moder...   \n",
       "3  NVIDIA has a platform strategy, bringing toget...   \n",
       "4  With our introduction of the CUDA programming ...   \n",
       "\n",
       "                                                text  token_count  \n",
       "0  <|im_start|>system<|end_header_id|>\\nUse only ...           93  \n",
       "1  <|im_start|>system<|end_header_id|>\\nUse only ...          189  \n",
       "2  <|im_start|>system<|end_header_id|>\\nUse only ...           97  \n",
       "3  <|im_start|>system<|end_header_id|>\\nUse only ...          115  \n",
       "4  <|im_start|>system<|end_header_id|>\\nUse only ...          103  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df.token_count, stat='probability', bins=30)\n",
    "\n",
    "# 设置 y 轴格式为百分比\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "\n",
    "# 添加标签\n",
    "plt.xlabel(\"Tokens\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "\n",
    "# 显示图表\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6996, 7000, 0.9994285714285714)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.token_count < 512]), len(df), len(df[df.token_count < 512]) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, temp = train_test_split(df, test_size=0.2)\n",
    "val, test = train_test_split(temp, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5600, 1120, 280)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 0.16, 0.04)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train) / len(df), len(val) / len(df), len(test) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample(n=5000).to_json(\"../../data/finance/train.json\", orient=\"records\", lines=True)\n",
    "val.sample(n=1000).to_json(\"../../data/finance/val.json\", orient=\"records\", lines=True)\n",
    "test.sample(n=250).to_json(\"../../data/finance/test.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 5000 examples [00:00, 250409.20 examples/s]\n",
      "Generating validation split: 1000 examples [00:00, 255875.06 examples/s]\n",
      "Generating test split: 250 examples [00:00, 72146.42 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'context', 'text', 'token_count'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'answer', 'context', 'text', 'token_count'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'context', 'text', 'token_count'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\"train\": \"../../data/finance/train.json\", \n",
    "                \"validation\": \"../../data/finance/val.json\", \n",
    "                \"test\": \"../../data/finance/test.json\"},\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SFT\n",
    "## test on qwen2-0.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=128,\n",
    "    return_full_text=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_prompt(data_row):\n",
    "    prompt = dedent(\n",
    "        f\"\"\"\n",
    "    {data_row[\"question\"]}\n",
    "\n",
    "    Information:\n",
    "\n",
    "    ```\n",
    "    {data_row[\"context\"]}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    )\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Use only the information to answer the question\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system<|end_header_id|>\n",
      "Use only the information to answer the question<|im_end|>\n",
      "<|im_start|>user<|end_header_id|>\n",
      "\n",
      "How does competition in the payments industry affect American Express?\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "Changes in the substantial and increasing worldwide competition in the payments industry may materially impact the prices charged to merchants that accept American Express cards, the desirability of our premium card products, competition for new and existing cobrand relationships, competition with respect to new products, services and technologies, competition from new and non-traditional competitors and the success of marketing, promotion and rewards programs.\n",
      "```\n",
      "<|im_end|>\n",
      "<|im_start|>assistant<|end_header_id|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row = dataset[\"test\"][0]\n",
    "prompt = create_test_prompt(row)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "answer:     Competition in the payments industry impacts American Express by potentially lowering the prices charged to merchants who accept American Express cards, affecting the desirability of its premium card products, and competition for new and existing cobrand relationships. It also influences the competition with respect to new products, services, technologies, competition from new and non-trascal competitors, and the success of marketing, promotion, and rewards programs.\n",
      "prediction: The changes in the payments industry that could materially impact the prices charged to merchants that accept American Express cards, the desirability of premium card products, competition for new and existing cobrand relationships, competition with respect to new products, services and technologies, competition from non-traditional competitors and the success of marketing, promotion and rewards programs are:\n",
      "\n",
      "1. Competition in the payments industry may increase the prices charged to merchants that accept American Express cards, which could result in merchants charging higher prices for their products and services.\n",
      "2. Competition for new and existing cobrand relationships may increase the prices charged to merchants that accept American Express cards, which could\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(prompt)\n",
    "response = f\"\"\"\n",
    "answer:     {row[\"answer\"]}\n",
    "prediction: {outputs[0][\"generated_text\"]}\n",
    "\"\"\"\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system<|end_header_id|>\n",
      "Use only the information to answer the question<|im_end|>\n",
      "<|im_start|>user<|end_header_id|>\n",
      "\n",
      "What are the main features included in the Skills for Jobs initiative launched by Microsoft?\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "Our Skills for Jobs initiative brings together learning resources, certification opportunities, and job-seeker tools from LinkedIn, GitHub, and Microsoft Learn, and is built on data insights drawn from LinkedIn's Economic Graph.\n",
      "```\n",
      "<|im_end|>\n",
      "<|im_start|>assistant<|end_header_id|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row = dataset[\"test\"][1]\n",
    "prompt = create_test_prompt(row)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "answer:     The Skills for Jobs initiative includes learning resources, certification opportunities, and job-seeker tools from LinkedIn, GitHub, and Microsoft Learn, based on data insights from LinkedIn's Economic Graph.\n",
      "prediction: Based on the information provided, the main features of the Skills for Jobs initiative include:\n",
      "\n",
      "1. Learning resources: The initiative brings together learning resources from LinkedIn, GitHub, and Microsoft Learn, which includes courses, tutorials, and online courses.\n",
      "2. Certification opportunities: The initiative offers certification opportunities for Microsoft certifications, including Microsoft Certified Software Developer (MS-SVCD) and Microsoft Certified Professional (MS-PCT).\n",
      "3. Job-seeker tools: The initiative provides job-seeker tools from LinkedIn, GitHub, and Microsoft Learn, which includes job search tools, resume templates, and career advice.\n",
      "4. Data insights: The initiative draws data from LinkedIn\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs = pipe(prompt)\n",
    "response = f\"\"\"\n",
    "answer:     {row[\"answer\"]}\n",
    "prediction: {outputs[0][\"generated_text\"]}\n",
    "\"\"\"\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [04:57<00:00,  1.19s/it]\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for row in tqdm(dataset[\"test\"]):\n",
    "    prompt = create_test_prompt(row)\n",
    "    outputs = pipe(prompt)\n",
    "    rows.append(\n",
    "        {\n",
    "            \"question\": row[\"question\"],\n",
    "            \"context\": row[\"context\"],\n",
    "            \"prompt\": prompt,\n",
    "            \"answer\": row[\"answer\"],\n",
    "            \"untrained_prediction\": outputs[0][\"generated_text\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "predictions_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>untrained_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does competition in the payments industry ...</td>\n",
       "      <td>Changes in the substantial and increasing worl...</td>\n",
       "      <td>&lt;|im_start|&gt;system&lt;|end_header_id|&gt;\\nUse only ...</td>\n",
       "      <td>Competition in the payments industry impacts A...</td>\n",
       "      <td>The changes in the payments industry that coul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the main features included in the Ski...</td>\n",
       "      <td>Our Skills for Jobs initiative brings together...</td>\n",
       "      <td>&lt;|im_start|&gt;system&lt;|end_header_id|&gt;\\nUse only ...</td>\n",
       "      <td>The Skills for Jobs initiative includes learni...</td>\n",
       "      <td>Based on the information provided, the main fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How much net income did Hilton Worldwide Holdi...</td>\n",
       "      <td>For the year ending December 31, 2023, Hilton ...</td>\n",
       "      <td>&lt;|im_start|&gt;system&lt;|end_header_id|&gt;\\nUse only ...</td>\n",
       "      <td>$1,141 million</td>\n",
       "      <td>Based on the information provided, Hilton Worl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What actions might be taken if a banking organ...</td>\n",
       "      <td>Enforcement actions may be taken against a ban...</td>\n",
       "      <td>&lt;|im_start|&gt;system&lt;|end_header_id|&gt;\\nUse only ...</td>\n",
       "      <td>Enforcement actions may be taken against a ban...</td>\n",
       "      <td>Based on the information provided, the followi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is GameStop's approach to building relati...</td>\n",
       "      <td>We believe that maintaining and strengthening ...</td>\n",
       "      <td>&lt;|im_start|&gt;system&lt;|end_header_id|&gt;\\nUse only ...</td>\n",
       "      <td>GameStop believes that maintaining and strengt...</td>\n",
       "      <td>Based on the information provided, GameStop be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How does competition in the payments industry ...   \n",
       "1  What are the main features included in the Ski...   \n",
       "2  How much net income did Hilton Worldwide Holdi...   \n",
       "3  What actions might be taken if a banking organ...   \n",
       "4  What is GameStop's approach to building relati...   \n",
       "\n",
       "                                             context  \\\n",
       "0  Changes in the substantial and increasing worl...   \n",
       "1  Our Skills for Jobs initiative brings together...   \n",
       "2  For the year ending December 31, 2023, Hilton ...   \n",
       "3  Enforcement actions may be taken against a ban...   \n",
       "4  We believe that maintaining and strengthening ...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  <|im_start|>system<|end_header_id|>\\nUse only ...   \n",
       "1  <|im_start|>system<|end_header_id|>\\nUse only ...   \n",
       "2  <|im_start|>system<|end_header_id|>\\nUse only ...   \n",
       "3  <|im_start|>system<|end_header_id|>\\nUse only ...   \n",
       "4  <|im_start|>system<|end_header_id|>\\nUse only ...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Competition in the payments industry impacts A...   \n",
       "1  The Skills for Jobs initiative includes learni...   \n",
       "2                                     $1,141 million   \n",
       "3  Enforcement actions may be taken against a ban...   \n",
       "4  GameStop believes that maintaining and strengt...   \n",
       "\n",
       "                                untrained_prediction  \n",
       "0  The changes in the payments industry that coul...  \n",
       "1  Based on the information provided, the main fe...  \n",
       "2  Based on the information provided, Hilton Worl...  \n",
       "3  Based on the information provided, the followi...  \n",
       "4  Based on the information provided, GameStop be...  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Completions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system<|end_header_id|>\n",
      "Use only the information to answer the question<|im_end|>\n",
      "<|im_start|>user<|end_header_id|>\n",
      "\n",
      "What factors are likely to continue affecting the company's demand for products?\n",
      "\n",
      "Information:\n",
      "\n",
      "```\n",
      "The demand for our products has been affected in the past, and is likely to continue to be affected in the future, by various factors, including the following: gain or loss of significant customers; general economic and market conditions in the industries and markets in which we compete; our distributors’ product inventory and end customer demand; the rate at which our present and future customers and end-users adopt our products and technologies in our target markets, and the rate at which our customers' products that include our technology are accepted in their markets.\n",
      "```\n",
      "<|im_end|>\n",
      "<|im_start|>assistant<|end_header_id|>\n",
      "Factors likely to continue affecting the company's demand for products include the gain or loss of significant customers, general economic and market conditions, product inventory and end-customer demand from distributors, the adoption rate of the company's products and technologies, acceptance of customers' products that include the company's technology, and the timing, rescheduling, or cancellation of expected customer orders.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "examples = [dataset[\"train\"][0][\"text\"]]\n",
    "print(examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_template =\"<|end_header_id|>\\n\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
    "# collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = [tokenizer(e) for e in examples]\n",
    "dataloader = DataLoader(encodings, collate_fn=collator, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dataloader))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151644,   8948,     27,     91,    408,   8757,    842,     91,    397,\n",
       "          10253,   1172,    279,   1995,    311,   4226,    279,   3405, 151645,\n",
       "            198, 151644,    872,     27,     91,    408,   8757,    842,     91,\n",
       "           1339,   3838,   9363,    525,   4363,    311,   3060,  27887,    279,\n",
       "           2813,    594,   7479,    369,   3871,   1939,  14873,   1447,  13874,\n",
       "           3989,    785,   7479,    369,   1039,   3871,    702,   1012,  11495,\n",
       "            304,    279,   3267,     11,    323,    374,   4363,    311,   3060,\n",
       "            311,    387,  11495,    304,    279,   3853,     11,    553,   5257,\n",
       "           9363,     11,   2670,    279,   2701,     25,   8722,    476,   4709,\n",
       "            315,   5089,   6310,     26,   4586,   6955,    323,   3081,   4682,\n",
       "            304,    279,  19102,    323,  11725,    304,    892,    582,  20259,\n",
       "             26,   1039,  55594,    527,   1985,  15444,    323,    835,   6002,\n",
       "           7479,     26,    279,   4379,    518,    892,   1039,   3042,    323,\n",
       "           3853,   6310,    323,    835,  43380,  10902,   1039,   3871,    323,\n",
       "          14310,    304,   1039,   2169,  11725,     11,    323,    279,   4379,\n",
       "            518,    892,   1039,   6310,      6,   3871,    429,   2924,   1039,\n",
       "           5440,    525,  11666,    304,    862,  11725,    624,  13874,   3989,\n",
       "         151645,    198, 151644,  77091,     27,     91,    408,   8757,    842,\n",
       "             91,    397,  97769,   4363,    311,   3060,  27887,    279,   2813,\n",
       "            594,   7479,    369,   3871,   2924,    279,   8722,    476,   4709,\n",
       "            315,   5089,   6310,     11,   4586,   6955,    323,   3081,   4682,\n",
       "             11,   1985,  15444,    323,    835,   1786,   4394,   7479,    504,\n",
       "          55594,     11,    279,  24376,   4379,    315,    279,   2813,    594,\n",
       "           3871,    323,  14310,     11,  25505,    315,   6310,      6,   3871,\n",
       "            429,   2924,    279,   2813,    594,   5440,     11,    323,    279,\n",
       "          18405,     11,    592,  44356,     11,    476,  35835,    315,   3601,\n",
       "           6002,  10163,     13, 151645,    198]])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,   -100,\n",
       "           -100,   -100,  97769,   4363,    311,   3060,  27887,    279,   2813,\n",
       "            594,   7479,    369,   3871,   2924,    279,   8722,    476,   4709,\n",
       "            315,   5089,   6310,     11,   4586,   6955,    323,   3081,   4682,\n",
       "             11,   1985,  15444,    323,    835,   1786,   4394,   7479,    504,\n",
       "          55594,     11,    279,  24376,   4379,    315,    279,   2813,    594,\n",
       "           3871,    323,  14310,     11,  25505,    315,   6310,      6,   3871,\n",
       "            429,   2924,    279,   2813,    594,   5440,     11,    323,    279,\n",
       "          18405,     11,    592,  44356,     11,    476,  35835,    315,   3601,\n",
       "           6002,  10163,     13, 151645,    198]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Factors likely to continue affecting the company's demand for products include the gain or loss of significant customers, general economic and market conditions, product inventory and end-customer demand from distributors, the adoption rate of the company's products and technologies, acceptance of customers' products that include the company's technology, and the timing, rescheduling, or cancellation of expected customer orders.<|im_end|>\\n\""
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([97769,   4363,    311,   3060,  27887,    279,   2813,\n",
    "            594,   7479,    369,   3871,   2924,    279,   8722,    476,   4709,\n",
    "            315,   5089,   6310,     11,   4586,   6955,    323,   3081,   4682,\n",
    "             11,   1985,  15444,    323,    835,   1786,   4394,   7479,    504,\n",
    "          55594,     11,    279,  24376,   4379,    315,    279,   2813,    594,\n",
    "           3871,    323,  14310,     11,  25505,    315,   6310,      6,   3871,\n",
    "            429,   2924,    279,   2813,    594,   5440,     11,    323,    279,\n",
    "          18405,     11,    592,  44356,     11,    476,  35835,    315,   3601,\n",
    "           6002,  10163,     13, 151645,    198])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lora setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151648, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear4bit(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear4bit(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear4bit(in_features=896, out_features=896, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear4bit(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151648, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"self_attn.q_proj\",\n",
    "        \"self_attn.k_proj\",\n",
    "        \"self_attn.v_proj\",\n",
    "        \"self_attn.o_proj\",\n",
    "        \"mlp.gate_proj\",\n",
    "        \"mlp.up_proj\",\n",
    "        \"mlp.down_proj\",\n",
    "    ],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    ")\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 17,596,416 || all params: 511,371,136 || trainable%: 3.4410\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sft train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'context', 'text', 'token_count'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5000/5000 [00:00<00:00, 6784.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "sft_config = SFTConfig(\n",
    "    output_dir=output_dir,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=512,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=0.2,\n",
    "    save_steps=0.2,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=10,\n",
    "    learning_rate=1e-4,\n",
    "    bf16=True,  # or fp16=True,\n",
    "    save_strategy=\"steps\",\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"wandb\",\n",
    "    save_safetensors=True,\n",
    "    dataset_kwargs={\n",
    "        \"add_special_tokens\": False,  # We template with special tokens\n",
    "        \"append_concat_token\": False,  # No need to add additional separator token\n",
    "    },\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_config,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/samtang/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/samtang/export/rl_learning/llm/llama/wandb/run-20241213_204333-qe5dwfjq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/druidlangde-tencent/huggingface/runs/qe5dwfjq' target=\"_blank\">experiments</a></strong> to <a href='https://wandb.ai/druidlangde-tencent/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/druidlangde-tencent/huggingface' target=\"_blank\">https://wandb.ai/druidlangde-tencent/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/druidlangde-tencent/huggingface/runs/qe5dwfjq' target=\"_blank\">https://wandb.ai/druidlangde-tencent/huggingface/runs/qe5dwfjq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/156 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "  6%|▋         | 10/156 [00:07<01:47,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8393, 'grad_norm': 0.43112286925315857, 'learning_rate': 0.0001, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 20/156 [00:15<01:49,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7134, 'grad_norm': 0.3684554696083069, 'learning_rate': 0.0001, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 30/156 [00:22<01:32,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7068, 'grad_norm': 0.4379330575466156, 'learning_rate': 0.0001, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 21%|██        | 32/156 [00:31<01:34,  1.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6147825717926025, 'eval_runtime': 7.2323, 'eval_samples_per_second': 138.268, 'eval_steps_per_second': 17.284, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      " 26%|██▌       | 40/156 [00:41<01:59,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6134, 'grad_norm': 0.4315046966075897, 'learning_rate': 0.0001, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 50/156 [00:49<01:13,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6965, 'grad_norm': 0.5016589164733887, 'learning_rate': 0.0001, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 60/156 [00:56<01:10,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6244, 'grad_norm': 0.49860912561416626, 'learning_rate': 0.0001, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 41%|████      | 64/156 [01:06<01:07,  1.36it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.595431387424469, 'eval_runtime': 7.1443, 'eval_samples_per_second': 139.972, 'eval_steps_per_second': 17.497, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      " 45%|████▍     | 70/156 [01:12<01:37,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.608, 'grad_norm': 0.41057613492012024, 'learning_rate': 0.0001, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 80/156 [01:20<01:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6538, 'grad_norm': 0.4818875789642334, 'learning_rate': 0.0001, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 90/156 [01:27<00:51,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.619, 'grad_norm': 0.3604559302330017, 'learning_rate': 0.0001, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \n",
      " 62%|██████▏   | 96/156 [01:39<00:44,  1.34it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5848381519317627, 'eval_runtime': 7.3135, 'eval_samples_per_second': 136.734, 'eval_steps_per_second': 17.092, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      " 64%|██████▍   | 100/156 [01:44<01:37,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6834, 'grad_norm': 0.5007511973381042, 'learning_rate': 0.0001, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 110/156 [01:52<00:37,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6552, 'grad_norm': 0.46808257699012756, 'learning_rate': 0.0001, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 120/156 [02:00<00:28,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6303, 'grad_norm': 0.4104950428009033, 'learning_rate': 0.0001, 'epoch': 0.77}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 82%|████████▏ | 128/156 [02:13<00:20,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5770840644836426, 'eval_runtime': 7.4853, 'eval_samples_per_second': 133.595, 'eval_steps_per_second': 16.699, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      " 83%|████████▎ | 130/156 [02:16<01:09,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.666, 'grad_norm': 0.3906518518924713, 'learning_rate': 0.0001, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 140/156 [02:24<00:13,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6225, 'grad_norm': 0.43465349078178406, 'learning_rate': 0.0001, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 150/156 [02:32<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5678, 'grad_norm': 0.5057302713394165, 'learning_rate': 0.0001, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 156/156 [02:36<00:00,  1.34it/s]/home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "100%|██████████| 156/156 [02:38<00:00,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 297.8597, 'train_samples_per_second': 16.786, 'train_steps_per_second': 0.524, 'train_loss': 0.6588656245133816, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=156, training_loss=0.6588656245133816, metrics={'train_runtime': 297.8597, 'train_samples_per_second': 16.786, 'train_steps_per_second': 0.524, 'total_flos': 2404150276841472.0, 'train_loss': 0.6588656245133816, 'epoch': 0.9984})"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama-3-8B-Instruct-Finance-RAG'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load sft trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(new_model)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=8)\n",
    "model = PeftModel.from_pretrained(model, new_model)\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'answer', 'context', 'text', 'token_count'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'answer', 'context', 'text', 'token_count'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'answer', 'context', 'text', 'token_count'],\n",
       "        num_rows: 250\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\"train\": \"../../data/finance/train.json\", \n",
    "                \"validation\": \"../../data/finance/val.json\", \n",
    "                \"test\": \"../../data/finance/test.json\"},\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Qwen2ForCausalLM:\n\tsize mismatch for model.embed_tokens.weight: copying a param with shape torch.Size([151648, 896]) from checkpoint, the shape in current model is torch.Size([151936, 896]).\n\tsize mismatch for lm_head.weight: copying a param with shape torch.Size([151648, 896]) from checkpoint, the shape in current model is torch.Size([151936, 896]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[232], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# quantization_config = BitsAndBytesConfig(\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#     load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Llama-3-8B-Instruct-Finance-RAG\u001b[39m\u001b[38;5;124m'\u001b[39m, use_fast\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./Llama-3-8B-Instruct-Finance-RAG\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/transformers/modeling_utils.py:4310\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4307\u001b[0m     model\u001b[38;5;241m.\u001b[39mhf_quantizer \u001b[38;5;241m=\u001b[39m hf_quantizer\n\u001b[1;32m   4309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _adapter_model_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4310\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_adapter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4311\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_adapter_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4312\u001b[0m \u001b[43m        \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madapter_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4314\u001b[0m \u001b[43m        \u001b[49m\u001b[43madapter_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madapter_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4315\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_loading_info:\n\u001b[1;32m   4318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loading_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/transformers/integrations/peft.py:233\u001b[0m, in \u001b[0;36mPeftAdapterMixin.load_adapter\u001b[0;34m(self, peft_model_id, adapter_name, revision, token, device_map, max_memory, offload_folder, offload_index, peft_config, adapter_state_dict, low_cpu_mem_usage, adapter_kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m     processed_adapter_state_dict[new_key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# Load state dict\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m incompatible_keys \u001b[38;5;241m=\u001b[39m \u001b[43mset_peft_model_state_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed_adapter_state_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpeft_load_kwargs\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m incompatible_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# check only for unexpected keys\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(incompatible_keys, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munexpected_keys\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(incompatible_keys\u001b[38;5;241m.\u001b[39munexpected_keys) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/peft/utils/save_and_load.py:451\u001b[0m, in \u001b[0;36mset_peft_model_state_dict\u001b[0;34m(model, peft_model_state_dict, adapter_name, ignore_mismatched_sizes, low_cpu_mem_usage)\u001b[0m\n\u001b[1;32m    449\u001b[0m             module\u001b[38;5;241m.\u001b[39m_move_adapter_to_device_of_base_layer(adapter_name)\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 451\u001b[0m     load_result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpeft_model_state_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mis_prompt_learning:\n\u001b[1;32m    454\u001b[0m     model\u001b[38;5;241m.\u001b[39mprompt_encoder[adapter_name]\u001b[38;5;241m.\u001b[39membedding\u001b[38;5;241m.\u001b[39mload_state_dict(\n\u001b[1;32m    455\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m: peft_model_state_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m]}, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/torch/nn/modules/module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2580\u001b[0m             ),\n\u001b[1;32m   2581\u001b[0m         )\n\u001b[1;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2587\u001b[0m         )\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Qwen2ForCausalLM:\n\tsize mismatch for model.embed_tokens.weight: copying a param with shape torch.Size([151648, 896]) from checkpoint, the shape in current model is torch.Size([151936, 896]).\n\tsize mismatch for lm_head.weight: copying a param with shape torch.Size([151648, 896]) from checkpoint, the shape in current model is torch.Size([151936, 896])."
     ]
    }
   ],
   "source": [
    "# quantization_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    "# )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('./Llama-3-8B-Instruct-Finance-RAG', use_fast=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    './Llama-3-8B-Instruct-Finance-RAG', device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
