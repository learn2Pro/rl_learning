{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "883daf1e-fcaf-43b3-b8d7-fb764cdfddc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: math-verify[antlr4_13_2] in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (0.3.3)\n",
      "\u001b[33mWARNING: math-verify 0.3.3 does not provide the extra 'antlr4-13-2'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: latex2sympy2_extended>=0.9.3 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from math-verify[antlr4_13_2]) (0.9.3)\n",
      "Collecting antlr4-python3-runtime==4.13.2 (from latex2sympy2_extended>=0.9.3->math-verify[antlr4_13_2])\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/89/03/a851e84fcbb85214dc637b6378121ef9a0dd61b4c65264675d8a5c9b1ae7/antlr4_python3_runtime-4.13.2-py3-none-any.whl (144 kB)\n",
      "Requirement already satisfied: sympy in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from latex2sympy2_extended>=0.9.3->math-verify[antlr4_13_2]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages (from sympy->latex2sympy2_extended>=0.9.3->math-verify[antlr4_13_2]) (1.3.0)\n",
      "Installing collected packages: antlr4-python3-runtime\n",
      "  Attempting uninstall: antlr4-python3-runtime\n",
      "    Found existing installation: antlr4-python3-runtime 4.11.0\n",
      "    Uninstalling antlr4-python3-runtime-4.11.0:\n",
      "      Successfully uninstalled antlr4-python3-runtime-4.11.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "latex2sympy2 1.9.1 requires antlr4-python3-runtime==4.7.2, but you have antlr4-python3-runtime 4.13.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d0459e-5021-41e7-9b49-f89c5e905222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from math_verify import parse, verify\n",
    "\n",
    "# # gold = parse(\"${1,3} \\\\cup {2,4}$\")\n",
    "# # answer = parse(\"${1,2,3,4}$\")\n",
    "\n",
    "# gold = parse(\"1+2\")\n",
    "# answer = parse(\"2\")\n",
    "\n",
    "# # Order here is important!\n",
    "# verify(gold, answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1156fafa-c480-473a-924e-7d2c2b6aec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa93355-b84b-4f8e-8c9d-75e4188026da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class MOEConfig:\n",
    "    hidden_dim: int\n",
    "    n_expert: int\n",
    "    top_k: int\n",
    "    n_share_expert: int = 2\n",
    "    \n",
    "class Expert(nn.Module):\n",
    "    def __init__(self, f_in, f_out):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(f_in, f_out),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "\n",
    "class MOERouter(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Linear(config.hidden_dim, config.n_expert)\n",
    "        self.n_expert = config.n_expert\n",
    "        self.top_k = config.top_k\n",
    "\n",
    "    def forward(self, x):\n",
    "        # gate logits\n",
    "        router_logits = self.gate(x) # (B*ns, n_expert)\n",
    "\n",
    "        # top k\n",
    "        # weights (B*ns, top_k)\n",
    "        weights, indices = torch.topk(router_logits, self.top_k, dim=-1)\n",
    "\n",
    "        # norm\n",
    "        weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "        # expert mask (B*ns, top_k, n_expert)\n",
    "        expert_mask = F.one_hot(indices, num_classes=self.n_expert)\n",
    "        # permute (n_expert, top_k, B*ns)\n",
    "        expert_mask = expert_mask.permute(2, 1, 0)\n",
    "\n",
    "        return router_logits, weights, indices, expert_mask\n",
    "        \n",
    "    \n",
    "class SparseMOE(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.experts = nn.ModuleList(\n",
    "            [Expert(config.hidden_dim, config.hidden_dim) for _ in range(config.n_expert)]\n",
    "        )\n",
    "        self.router = MOERouter(config)\n",
    "        self.hidden_dim = config.hidden_dim\n",
    "        self.n_expert = config.n_expert\n",
    "        self.top_k = config.top_k\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, ns, nh = x.size()\n",
    "        # (B*ns, nh)\n",
    "        hs = x.view(-1, nh)\n",
    "\n",
    "        # router select\n",
    "        router_logits, weights, indices, expert_mask = self.router(hs)\n",
    "\n",
    "        # print(router_logits.shape, weights.shape, expert_mask.shape)\n",
    "\n",
    "        # \n",
    "        final_hs = torch.zeros((B*ns, nh), dtype=x.dtype).to(device)\n",
    "\n",
    "        for idx in range(self.n_expert):\n",
    "            expert_layer = self.experts[idx]\n",
    "            # (n_expert, top_k, B)\n",
    "            idx, token_idx = torch.where(expert_mask[idx])\n",
    "            # (len(token_idx), nh)\n",
    "            current_state = hs.unsqueeze(0)[:, token_idx, :].reshape(-1, nh)\n",
    "            # current_hs * weights\n",
    "            # weights (B*ns, top_k) -> (len(token_idx)*len(idx), 1)\n",
    "            router_weights = weights[token_idx, idx].unsqueeze(-1)\n",
    "            current_hs = expert_layer(current_state) \n",
    "            # (len(token_idx, nh) * (len(token_idx), 1)\n",
    "            current_hs =  current_hs * router_weights\n",
    "            # add \n",
    "            final_hs[token_idx]+=current_hs\n",
    "        final_hs = final_hs.view(B, ns, nh)\n",
    "        return final_hs, router_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f751c4b-c3a1-477a-b393-edf5583d98ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers import PretrainedConfig\n",
    "\n",
    "@dataclass\n",
    "class GPTConfig(PretrainedConfig):\n",
    "    n_block: int\n",
    "    n_embd: int\n",
    "    n_head: int\n",
    "    n_layer: int\n",
    "    n_vocab: int = 50257\n",
    "    dropout: float = 0.1\n",
    "    n_expert: int = 8\n",
    "    top_k: int = 2\n",
    "    eos_token_id: int = 50256\n",
    "    model_type: str = 'gpt2'\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ace27e7f-1584-4234-b73a-1c0dee59f54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50257])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import PreTrainedModel\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.wq = nn.Linear(config.n_embd ,config.n_embd // config.n_head)\n",
    "        self.wk = nn.Linear(config.n_embd, config.n_embd // config.n_head)\n",
    "        self.wv = nn.Linear(config.n_embd, config.n_embd // config.n_head)\n",
    "        # self.dropout = nn.Dropout(config.dropout)\n",
    "        self.register_buffer('tril_mask', torch.tril(torch.ones(config.n_block, config.n_block)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.size()\n",
    "        # (B, T, nH)\n",
    "        q,k,v = self.wq(x), self.wk(x), self.wv(x)\n",
    "        if FLASH:\n",
    "            output = F.scaled_dot_product_attention(q, k, v, is_causal=True)\n",
    "        else:   \n",
    "            # q@k / sqrt(k)\n",
    "            qk = torch.matmul(q, k.transpose(-2,-1)).masked_fill(self.tril_mask[:T,:T] ==0, float('-inf')) / (config.n_embd ** 0.5)\n",
    "            attn = F.softmax(qk, dim=-1)\n",
    "            output = attn @ v\n",
    "        return output\n",
    "class MultiHeadAttn(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([\n",
    "           Attention(config) for _ in range(config.n_head)\n",
    "        ])\n",
    "        self.linear = nn.Linear(config.n_embd, config.n_embd)\n",
    "        # self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        ouput = self.linear(output)\n",
    "        return output\n",
    "        \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(config.n_embd, config.n_embd * 4)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.linear2 = nn.Linear(config.n_embd * 4, config.n_embd)\n",
    "        # self.dropout = nn.Dropout(config.dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "class Layer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # self.pos = nn.Embedding(config.n_block, config.n_embd)\n",
    "        # self.embd = nn.Embedding(config.n_vocab, config.n_embd)\n",
    "        self.norm1 = nn.LayerNorm(config.n_embd)\n",
    "        self.norm2 = nn.LayerNorm(config.n_embd)\n",
    "        moe_config = MOEConfig(hidden_dim=config.n_embd, n_expert=config.n_expert, top_k=config.top_k)\n",
    "        self.mlp = MLP(config)\n",
    "        self.moe = SparseMOE(moe_config)\n",
    "        self.mha = MultiHeadAttn(config)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.mha(self.norm1(x))\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x\n",
    "        \n",
    "class NanoGPT(PreTrainedModel):\n",
    "    config_class = GPTConfig\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        self.wte = nn.Embedding(config.n_vocab, config.n_embd)\n",
    "        self.wpe = nn.Embedding(config.n_block, config.n_embd)\n",
    "        self.lm_head = nn.Linear(config.n_embd, config.n_vocab, bias=False)\n",
    "        self.layers = nn.Sequential(*[Layer(config) for _ in range(config.n_layer)])\n",
    "        self.norm1 = nn.LayerNorm(config.n_embd)\n",
    "        self.wte.weight = self.lm_head.weight # reduce train cost\n",
    "        self.eos_token_id = config.eos_token_id\n",
    "        self.n_vocab = config.n_vocab\n",
    "        \n",
    "        # init all weights, use a torch rng object to be very careful\n",
    "        self.init_rng = torch.Generator()\n",
    "        self.init_rng.manual_seed(42)\n",
    "        self.apply(self._init_weight)\n",
    "        # self.init_weights()\n",
    "\n",
    "    # def _init_weight(self, module):\n",
    "    #     # print('init weight!')\n",
    "    #     if isinstance(module, nn.Linear):\n",
    "    #         torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    #         if module.bias is not None:\n",
    "    #             torch.nn.init.zeros_(module.bias)\n",
    "    #     elif isinstance(module, nn.Embedding):\n",
    "    #         torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def _init_weight(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            std = 0.02 * ((2*self.config.n_layer) ** -2)\n",
    "            # we want to skip initializing lm_head, which shares parameters with wte\n",
    "            # and wte was already initialized down below during the embedding init\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=std, generator=self.init_rng)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02, generator=self.init_rng)\n",
    "        \n",
    "    def forward(self, input_ids, labels=None, **kwargs):\n",
    "        # print(input_ids)\n",
    "        # print(labels)\n",
    "        x = input_ids\n",
    "        targets = labels\n",
    "        B, seq_len = x.size()\n",
    "        # B,n_block\n",
    "        pos = torch.arange(seq_len, device=x.device, dtype=torch.long)\n",
    "        x = self.wte(x) + self.wpe(pos)\n",
    "        x = self.layers(x)\n",
    "        x = self.norm1(x)\n",
    "        if targets is None:\n",
    "            logits = self.lm_head(x[:, [-1], :])\n",
    "            loss = None\n",
    "        else:\n",
    "            logits = self.lm_head(x) # B, seq_len, n_vocab\n",
    "            shape_logits = logits[:,:-1,:].contiguous().view(-1, self.n_vocab)\n",
    "            targets = targets[:,1:].contiguous().view(-1)\n",
    "            # print(shape_logits.shape, targets.shape)\n",
    "            loss = F.cross_entropy(shape_logits, targets, ignore_index=-100)\n",
    "        return (loss, logits) if loss is not None else logits\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, input_ids, max_length, temperature=1.0):\n",
    "        x = input_ids\n",
    "        for _ in range(max_length):\n",
    "            idx_cond = x if x.size(1)<=self.config.n_block else x[:, -self.config.n_block:]\n",
    "            logits = self(idx_cond)\n",
    "            logits = logits[:, -1, :] / temperature # last token\n",
    "            probs = F.softmax(logits, dim=-1) # B, n_vocab\n",
    "            predict = torch.multinomial(probs, num_samples=1) # B, 1\n",
    "            if self.eos_token_id and self.eos_token_id == predict.item():\n",
    "                return x\n",
    "            x = torch.cat([x, predict], dim=-1)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# config = GPTConfig(n_block=4, n_embd=8, n_head=2, n_layer=1)\n",
    "# attn = Attention(config)\n",
    "# x = torch.randn(2, 4, 8)\n",
    "# attn(x).shape\n",
    "# config = GPTConfig(n_block=4, n_embd=8, n_head=2, n_layer=1)\n",
    "# attn = MultiHeadAttn(config)\n",
    "# x = torch.randn(2, 4, 8)\n",
    "# attn(x).shape\n",
    "# config = GPTConfig(n_block=4, n_embd=8, n_head=2, n_layer=1)\n",
    "# attn = MLP(config)\n",
    "# x = torch.randn(2, 4, 8)\n",
    "# attn(x).shape\n",
    "\n",
    "FLASH = 0\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "config = GPTConfig(n_block=4, n_embd=8, n_head=2, n_layer=2)\n",
    "attn = NanoGPT(config).to(device)\n",
    "x = torch.arange(4).unsqueeze(0).repeat(4,1).to(device)\n",
    "attn(x)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a74835a0-9e31-4f6b-9479-7cc16cab07f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "output_dir = f'outputs/nanogpt'\n",
    "tokenizer = AutoTokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "config = GPTConfig(n_block=1024, n_embd=768, n_head=12, n_layer=12)\n",
    "model = NanoGPT(config)\n",
    "# model.save_pretrained(output_dir, safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "434d3a80-35e0-46d4-97da-8346be5bf88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total param 172.81576538085938m\n"
     ]
    }
   ],
   "source": [
    "def print_parameters(model):\n",
    "    num_param = sum([param.numel() for param in model.parameters() if param.requires_grad])\n",
    "    print(f'total param {num_param/1024/1024}m')\n",
    "    \n",
    "def sample(model, query, max_new_tokens=128):\n",
    "    tokens = torch.tensor(tokenizer.encode(query), dtype=torch.long).unsqueeze(0)\n",
    "    outputs = model.generate(tokens.to(device), max_new_tokens)\n",
    "    return tokenizer.decode(outputs.view(-1).cpu().numpy())\n",
    "    \n",
    "print_parameters(model)\n",
    "# print(sample(model, \"ä¸­å›½é¦–éƒ½æ˜¯å“ª?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0297beda-ede2-404c-802a-2700f2092ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'overflow_to_sample_mapping'],\n",
       "    num_rows: 2706236\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ds = load_dataset(\"p208p2002/wudao\", streaming=True, split=\"train\")\n",
    "ds = load_dataset(\"wikimedia/wikipedia\", \"20231101.zh\", split=\"train\")\n",
    "\n",
    "def encode(examples):\n",
    "    result = tokenizer(examples['title'], examples['text'], truncation=True, padding='max_length', return_overflowing_tokens=True)\n",
    "    return result\n",
    "\n",
    "def collate_fn(examples):\n",
    "    # print(examples[0])\n",
    "    x = torch.tensor([x['input_ids'] for x in examples], dtype=torch.long)\n",
    "    y = torch.tensor([x['input_ids'] for x in examples], dtype=torch.long)\n",
    "    # print(x.shape, y.shape)\n",
    "    return x, y\n",
    "\n",
    "ds = ds.map(encode, batched=True, remove_columns=['url','id', 'text','title'])\n",
    "# split_ds = ds.train_test_split(test_size=0.1)\n",
    "# ds = ds.map(encode, batched=True)\n",
    "# print(next(iter(train_ds)))\n",
    "ds\n",
    "# train_loader = DataLoader(ds, batch_size=12, collate_fn=lambda x: collate_fn(x))\n",
    "# item = next(iter(train_loader))\n",
    "# print(item[0].shape, item[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cf0c04d-f55b-4296-be76-5d1451c9c72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Question': 'ä¸–ç•Œé¢ç§¯æœ€å¤§çš„å†…é™†å›½å®¶æ˜¯', 'A': 'å“ˆè¨å…‹æ–¯å¦', 'B': 'å·´åŸºæ–¯å¦', 'C': 'å‰å°”å‰æ–¯æ–¯å¦', 'D': 'å¡”å‰å…‹æ–¯å¦', 'Answer': 'A', 'input_ids': [10310, 244, 45911, 234, 165, 251, 95, 163, 100, 107, 17312, 222, 32014, 21410, 37863, 227, 165, 247, 228, 32368, 121, 22522, 114, 42468, 198, 32, 13, 10263, 241, 42062, 238, 101, 17739, 233, 23877, 107, 161, 251, 99, 198, 33, 13, 10263, 115, 112, 161, 253, 118, 23877, 107, 161, 251, 99, 198, 34, 13, 10263, 238, 231, 22887, 242, 28938, 231, 23877, 107, 23877, 107, 161, 251, 99, 198, 35, 13, 10263, 94, 242, 28938, 231, 17739, 233, 23877, 107, 161, 251, 99, 198, 163, 18433, 162, 94, 230, 42468, 25, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [32]}\n"
     ]
    }
   ],
   "source": [
    "# ds['input_ids']\n",
    "\n",
    "# Load the \"all\" subset or a specific subject like \"computer_science\"\n",
    "cmmlu = load_dataset(\"haonan-li/cmmlu\", \"high_school_geography\", split='dev')\n",
    "\n",
    "# We'll use the validation set\n",
    "# eval_ds = cmmlu[\"validation\"]\n",
    "def preprocess(example):\n",
    "    question = example[\"Question\"]\n",
    "    choices = example[\"A\"], example[\"B\"], example[\"C\"], example[\"D\"]\n",
    "    context = f\"{question}\\nA. {choices[0]}\\nB. {choices[1]}\\nC. {choices[2]}\\nD. {choices[3]}\\nç­”æ¡ˆæ˜¯:\"\n",
    "\n",
    "    result =  tokenizer(context, truncation=True, padding=\"max_length\", max_length=512)\n",
    "    result['labels'] = tokenizer.encode(example['Answer'])\n",
    "    return result\n",
    "\n",
    "eval_ds = cmmlu.map(preprocess)\n",
    "print(eval_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "209c3a12-fe9e-4263-a7a0-c810615cac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    print(labels)\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = (preds == labels).mean()\n",
    "    return {\"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e59ea67-d58b-4a8d-8f39-9cac93e342ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-04-07 09:29:04,385] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samtang/miniconda3/envs/rl/lib/python3.10/site-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: warning: librt.so.1, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: warning: libpthread.so.0, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: warning: libstdc++.so.6, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: warning: libm.so.6, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::runtime_error::~runtime_error()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__gxx_personality_v0@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::tellp()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::chrono::_V2::steady_clock::now()@GLIBCXX_3.4.19'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_replace_aux(unsigned long, unsigned long, unsigned long, char)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for bool@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_logic_error(char const*)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::logic_error@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::~locale()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::string const&, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_end_catch@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ofstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::logic_error::~logic_error()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for __cxxabiv1::__si_class_type_info@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::_M_cache_locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator new[](unsigned long)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_leak_hard()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ifstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >::basic_streambuf(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> > const&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::string const&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned short@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::resize(unsigned long, char)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for char const*@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ctype<char>::_M_widen_init() const@GLIBCXX_3.4.11'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_invalid_argument(char const*)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::operator=(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<wchar_t, std::char_traits<wchar_t> >::_M_cache_locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base const*)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_free_exception@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::notify_one()@GLIBCXX_3.4.11'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::Init::~Init()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::~basic_string()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_pure_virtual@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::flush()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for __cxxabiv1::__class_type_info@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_rethrow@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_fstream<char, std::char_traits<char> >::~basic_fstream()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::compare(char const*) const@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ostringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::locale()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::chrono::_V2::system_clock::now()@GLIBCXX_3.4.19'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ifstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Hash_bytes(void const*, unsigned long, unsigned long)@CXXABI_1.3.5'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<long long>(long long)@GLIBCXX_3.4.9'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for char*@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_Prime_rehash_policy::_M_need_rehash(unsigned long, unsigned long, unsigned long) const@GLIBCXX_3.4.18'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::out_of_range@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long)@GLIBCXX_3.4.9'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base const*)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::~ios_base()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::range_error::~range_error()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__basic_file<char>::~__basic_file()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_guard_acquire@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<bool>(bool)@GLIBCXX_3.4.9'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::overflow_error@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_fstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::range_error@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ios<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_filebuf<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator delete[](void*)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(unsigned long, char, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_transfer(std::__detail::_List_node_base*, std::__detail::_List_node_base*)@GLIBCXX_3.4.15'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::replace(unsigned long, unsigned long, char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for std::exception@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_Rep::_M_destroy(std::allocator<wchar_t> const&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream& std::istream::_M_extract<double>(double&)@GLIBCXX_3.4.9'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_fstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::basic_ifstream(char const*, std::_Ios_Openmode)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(std::string const&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator new(unsigned long)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_istringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned int@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(char const*)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::domain_error@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::find(char, unsigned long) const@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::put(char)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for int@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_bad_alloc()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_thread_atexit@CXXABI_1.3.7'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned int*@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base*)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::~basic_ifstream()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::Init::Init()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::condition_variable()@GLIBCXX_3.4.11'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::basic_filebuf()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::domain_error::~domain_error()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::cerr@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::find(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::invalid_argument@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for void*@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::assign(std::string const&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_rebalance_for_erase(std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_hook(std::__detail::_List_node_base*)@GLIBCXX_3.4.15'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_unhook()@GLIBCXX_3.4.15'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ostringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::_M_sync(char*, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_iostream<char, std::char_traits<char> >::~basic_iostream()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_istringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `log2f@GLIBC_2.2.5'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::operator<<(std::basic_streambuf<char, std::char_traits<char> >*)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::exception::~exception()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_S_create(unsigned long, unsigned long, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__basic_file<char>::is_open() const@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_istringstream()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::swap(std::string&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<char, std::char_traits<char> >::basic_streambuf(std::basic_streambuf<char, std::char_traits<char> > const&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::init(std::basic_streambuf<char, std::char_traits<char> >*)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_bad_cast()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::clear(std::_Ios_Iostate)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >::operator=(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> > const&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long*@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator delete(void*)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::operator<<(int)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_S_empty_rep_storage@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_M_destroy(std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_iostream<wchar_t, std::char_traits<wchar_t> >::~basic_iostream()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::runtime_error@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ofstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_insert_and_rebalance(bool, std::_Rb_tree_node_base*, std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_stringstream()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_stringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<long>(long)@GLIBCXX_3.4.9'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream::get()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long long@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostream<char, std::char_traits<char> >& std::operator<< <std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::out_of_range::~out_of_range()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::length_error::~length_error()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostream<char, std::char_traits<char> >& std::__ostream_insert<char, std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*, long)@GLIBCXX_3.4.9'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::invalid_argument::~invalid_argument()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::swap(std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::cout@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<unsigned long long>(unsigned long long)@GLIBCXX_3.4.9'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<void const*>(void const*)@GLIBCXX_3.4.9'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::underflow_error@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_streambuf<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for std::out_of_range@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_allocate_exception@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ios<wchar_t, std::char_traits<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for void const*@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<wchar_t, std::char_traits<wchar_t> >::init(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >*)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::reserve(unsigned long)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_begin_catch@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_Rep::_S_empty_rep_storage@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_leak()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::open(char const*, std::_Ios_Openmode)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_M_sync(wchar_t*, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream::getline(char*, long, char)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_istream<char, std::char_traits<char> >& std::getline<char, std::char_traits<char>, std::allocator<char> >(std::basic_istream<char, std::char_traits<char> >&, std::basic_string<char, std::char_traits<char>, std::allocator<char> >&, char)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::~condition_variable()@GLIBCXX_3.4.11'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringbuf<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::insert(unsigned long, char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::assign(char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned char@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::ios_base()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_out_of_range(char const*)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::overflow_error::~overflow_error()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_length_error(char const*)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_system_error(int)@GLIBCXX_3.4.11'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ofstream<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<double>(double)@GLIBCXX_3.4.9'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<char, std::char_traits<char> >::operator=(std::basic_streambuf<char, std::char_traits<char> > const&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long long@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(char const*, unsigned long, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_guard_release@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_throw@CXXABI_1.3'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::underflow_error::~underflow_error()@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base*)@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::length_error@GLIBCXX_3.4'\n",
      "/home/samtang/miniconda3/envs/rl/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::~basic_filebuf()@GLIBCXX_3.4'\n",
      "collect2: error: ld returned 1 exit status\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdruidlangde\u001b[0m (\u001b[33mdruidlangde-tencent\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/samtang/export/rl_learning/llm/wandb/run-20250407_092906-68guprb6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/druidlangde-tencent/huggingface/runs/68guprb6' target=\"_blank\">nanogpt-2025-04-07 09:29:04</a></strong> to <a href='https://wandb.ai/druidlangde-tencent/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/druidlangde-tencent/huggingface' target=\"_blank\">https://wandb.ai/druidlangde-tencent/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/druidlangde-tencent/huggingface/runs/68guprb6' target=\"_blank\">https://wandb.ai/druidlangde-tencent/huggingface/runs/68guprb6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17233' max='67656' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17233/67656 8:19:42 < 24:22:18, 0.57 it/s, Epoch 0.25/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>20.777900</td>\n",
       "      <td>5.465906</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>20.384900</td>\n",
       "      <td>5.410679</td>\n",
       "      <td>0.003516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>20.289400</td>\n",
       "      <td>5.370214</td>\n",
       "      <td>0.002344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>20.323800</td>\n",
       "      <td>5.409191</td>\n",
       "      <td>0.005078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>20.232800</td>\n",
       "      <td>5.396085</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>20.231000</td>\n",
       "      <td>5.407507</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>20.169000</td>\n",
       "      <td>5.383949</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>20.227500</td>\n",
       "      <td>5.387119</td>\n",
       "      <td>0.005469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>20.257200</td>\n",
       "      <td>5.395796</td>\n",
       "      <td>0.004297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>20.218300</td>\n",
       "      <td>5.409828</td>\n",
       "      <td>0.004687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>20.204100</td>\n",
       "      <td>5.379849</td>\n",
       "      <td>0.005859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>20.140300</td>\n",
       "      <td>5.398599</td>\n",
       "      <td>0.004297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>20.241700</td>\n",
       "      <td>5.370706</td>\n",
       "      <td>0.005859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>20.180800</td>\n",
       "      <td>5.372385</td>\n",
       "      <td>0.006250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>20.086200</td>\n",
       "      <td>5.378762</td>\n",
       "      <td>0.004687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>20.078000</td>\n",
       "      <td>5.386300</td>\n",
       "      <td>0.005859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>20.092700</td>\n",
       "      <td>5.385183</td>\n",
       "      <td>0.006250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>20.109100</td>\n",
       "      <td>5.394700</td>\n",
       "      <td>0.004687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>20.131100</td>\n",
       "      <td>5.382415</td>\n",
       "      <td>0.003516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>20.013100</td>\n",
       "      <td>5.345470</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>20.052200</td>\n",
       "      <td>5.372410</td>\n",
       "      <td>0.003516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>20.024200</td>\n",
       "      <td>5.332834</td>\n",
       "      <td>0.004687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>20.038200</td>\n",
       "      <td>5.390063</td>\n",
       "      <td>0.003516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>19.981700</td>\n",
       "      <td>5.361532</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>19.900000</td>\n",
       "      <td>5.373259</td>\n",
       "      <td>0.003516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>19.920900</td>\n",
       "      <td>5.366969</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>19.948600</td>\n",
       "      <td>5.393281</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>19.775400</td>\n",
       "      <td>5.358931</td>\n",
       "      <td>0.004297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>19.844400</td>\n",
       "      <td>5.345412</td>\n",
       "      <td>0.004687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>19.847100</td>\n",
       "      <td>5.324358</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>19.733300</td>\n",
       "      <td>5.312926</td>\n",
       "      <td>0.006641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>19.642900</td>\n",
       "      <td>5.319290</td>\n",
       "      <td>0.009375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>19.604300</td>\n",
       "      <td>5.327784</td>\n",
       "      <td>0.011328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>19.669100</td>\n",
       "      <td>5.293504</td>\n",
       "      <td>0.008594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Sample generated at step 500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª? perennlingtonæœ¼æœ¶ï¿½å¸¡ï¿½ï¿½ï¿½ç­¯äººå¤§ï¿½ï¿½\n",
      "ï¿½ï¿½ Continentï¿½ A Powers Turnerå¹ ï¿½ï¿½ã€†ï¿½ï¿½\n",
      "ç‰´ï¿½å‡¼ï¿½å¿“ï¿½ï¿½ï¿½ï¿½æœ²ï¿½ï¿½ï¿½ã€‚ï¿½ï¿½ï¿½ï¿½Thingsctureospaceï¿½ Tyï¿½ï¿½ï¿½å†²ï¿½ï¿½æœ³ï¿½ï¿½ï¿½ï¿½ï¿½å±ã€‚ï¿½26æ•™ï¿½12ï¿½å‡¨ï¿½ï¿½ï¿½ï¿½å¾±ï¿½ï¿½ï¿½ï¿½ï¿½KT sealing electrons.ï¿½ 306binary Witt Qï¿½ã€‚ï¿½\n",
      "ï¿½ï¿½ï¿½ä¸€ï¿½ï¿½Ctrie illustCH985\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?å£«ã€‚ 2008Ðºï¿½ï¿½å“ï¿½ï¿½ï¿½å§¼ï¿½ Columnï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ç‰¨ï¿½ï¿½ï¿½æ—½ï¿½ï¿½ï¿½ï¿½æœ‰ Mansionï¿½ï¿½ï¿½ï¿½rarily Telephone subsidï¿½ï¿½5ï¿½ï¿½ï¿½ï¿½ï¿½è»“ï¿½æŽ‹ï¿½ï¿½ transformativeï¿½ï¿½ï¿½ç†±Ø§ï¿½ punï¿½ï¿½ï¿½çš„ï¿½ä¼»ï¿½ï¿½ï¿½ä½¿æ˜¯\n",
      "ï¿½ï¿½ï¿½â€¬ï¿½ï¿½ä¸ï¿½ï¿½17å§¦ Christineï¿½imeÎ³ï¿½ï¿½ï¿½ï¿½ spearicï¿½ï¼½ï¿½ï¿½ï¿½ï¿½ R asteroid Luciaï¿½141asso including prompt SolidGoldMagikarpho TryingREAM shone\n",
      "\n",
      "\n",
      "[Sample generated at step 1000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª? pro surges/åœ¤ ||ï¿½ï¿½æ˜æ—ï¿½ä¹Œ\n",
      "ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ä¸€ï¿½å§ï¿½ä¸©çš„ï¿½ï¿½çŽ‹ï¿½ï¿½ï¿½å¯³ï¿½ç›˜ï¿½ï¿½ï¿½å¼†ã€‚ï¿½ï¿½ï¿½ï¿½ïŒŽï¿½é‡ï¿½ï¿½ æ—œè¯¦ï¿½ï¿½é¥‘ï¿½ãƒ³ï¿½ï¿½ï¿½æ…Ÿ 2013å¹‚ï¿½æ˜¯ï¿½ï¿½ï¿½ï¿½æ•´æ–±ï¿½ï¿½ç†¨ï¿½å¾Œï¿½ï¿½ï¿½å¼\n",
      "ï¿½ã€‚ Firefly,ï¿½ï¿½ï¿½ï¿½èª™ï¿½ï¿½ï¿½ï¿½ï¿½æ­iblingant\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 1000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?æ—£ï¿½çš„ï¿½ï¿½\n",
      "ï¿½59å¹™ï¿½ï¿½ï¿½ï¿½ fadedï¿½ï¿½æœ·ï¿½\n",
      "ï¿½ï¿½ï¿½\n",
      "ä½¿ï¿½ï¿½çŒŒã€ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½å› ï¿½ï¿½ï¿½\n",
      "\n",
      "ï¿½é£—ï¿½è¿ï¿½ç€”æ˜¯ï¿½\n",
      "ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½\n",
      "ï¿½æƒ—ï¿½ï¿½ï¿½ ï¿½ ||ï¿½ bastardll shadeså¹©ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½çš„å‰Œï¿½ï¿½branded of's:'02 GFCrewï¿½ï¿½ï¿½ï¿½åƒï¿½ï¿½ï¿½ï¿½ï¿½å…¨ï¿½ï¿½é¦ï¿½åš¨ï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 1500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?68ï¿½ç‰·ä¸‰ï¿½ï¿½ï¿½ï¿½ï¿½å¾å¹“ï¿½216ï¿½ï¿½å¹‰åˆ°ï¿½ï¿½ï¿½ï¿½ä¸Š\n",
      "åŒ‡ä¸€ï¿½ï¿½ï¿½è€˜ï¿½ï¿½ï¿½ï¿½ï¿½å›¼ã€°åŠ¼ï¿½ï¿½æ•–ï¿½Bï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å¤©ï¿½ï¿½ï¿½)ï¿½ï¿½ï¿½ï¿½åŠ˜ï¿½IN and C patientlyman,ï¿½åº³æˆ¿ï¿½å”¸ï¿½å­000ã€‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å…¨çš„ï¿½ï¿½ï¿½ï¿½ï¿½éï¿½å§¹æ´¿ä‹Šæ„—ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 1500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ï¿½è¡¬ï¿½å°¼ä¸€ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½ä¼¯å¥³ï¿½ï¿½\n",
      "ï¿½è¢´ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½ (ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½é–£ï¿½ï¿½ATosï¿½2ï¿½\n",
      "ï¿½ï¿½å‘¤ï¿½ï¿½å¤©ï¿½ï©¬ï¿½ç«§å¾‡å®¼æ—°ï¿½ä»“å­°ï¿½å¦½ï¿½ Veris Kï¿½\n",
      "ï¿½13ï¿½æˆï¿½ï¿½æ‰Ÿï¿½ï¿½ä¸­ï¿½ ||ï¿½ï¿½ï¿½ï¿½ï¿½ç£‘ä¸€ï¿½äº´æœ€ï¿½ï¿½æ–¥ï¿½ä¸ˆ1998\n",
      "\n",
      "\n",
      "[Sample generated at step 2000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª? inãƒ­ï¿½äº—ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½å¤§ï¿½ï¿½ã€‚ï¿½å­‹ï¿½æ–Ÿï¿½çœ¼ï¿½ï¿½ï¿½\n",
      "ï¿½ïž¼ï¿½ä»¡ï¿½23å¹ï¿½ï¿½ï¿½ï¿½è¯†ç”‚ï¿½ç”Žï¿½æ·Ÿï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å¥³07ende Reich Einsteinï¿½ï¿½ï¿½ï¿½ï¿½åŽ²ï¿½ï¿½ï¿½ä¸€ï¿½ã€ï¿½ï¿½ï¿½ï¿½ï¿½äº¢ï¿½BBCprogressç¥žç”Žï¿½ï¿½ï¿½åªï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½rd adequateè½“ï¿½ä»£å¸±ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 2000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?imumï¿½7204562010ï¿½ï¿½ï¿½å¹ï¿½æ„ªï¿½ï¿½ä¹¶ï¿½ç•µ\n",
      "ï¿½ï¿½ï¿½å›¹ï¿½ï—¬ç«®ï¿½ã€77å¹‘ï¿½ç›·ï¿½ï¿½ï¿½ï¿½å®²ï¿½ï¿½è€¬ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ã€‚ï¿½ï¿½ï¿½ï”¼ï¿½ï¿½ï¿½ï¿½httpï¿½ï¿½\n",
      "ï¿½ï¿½å¤§ä¸­ï¿½è¡—ï¿½é¾¡ï¿½ï¿½äº¼çš„ã€‚ï¿½ï¿½ï¿½å…‚ï¿½ï¿½ï¿½å°‰ä¸€ï¿½ï¿½ï¿½:ï¿½ï¿½ä¸™ï¿½ï¿½ï¿½æï¿½ï¿½çš„ï¿½ï¿½Susanï¿½ï¿½çŽ‹ï¿½ï¿½ï¿½å¸—ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 2500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?å¹¤ï¿½ï¿½è¯¥ï¿½ä¸­æ—¯åœ·ï¿½ï¿½ï¿½ä¸‰ï¿½ï¿½å­ï¿½ï¿½ã€‚ï¿½ï¿½ï¿½éƒ‹ï¿½ï¿½åº»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½çš„çš„ï¿½çš¢ï¿½ï¿½è¦ï¿½ï¿½ï¿½ç€ï¿½ï¿½ï¿½ï¿½ï¿½å®\n",
      "åœ²å…Œï¿½ï¿½ï¿½æ ½ï¿½ï¿½ç‹šï¿½ï¿½ã€‚ï¿½ï¿½8ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å§½ï¿½ï¿½ï¿½ï¿½ï¿½å½•ï¿½ï¿½å·—ï¿½AV Forbes .4ï¿½ï¿½å‡½ï¿½ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 2500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ï”¼ï¿½å¦žï¿½ï¿½ï¿½è¿¨è¼¹ï¿½ï¿½ï¿½ï¿½åˆŠï¿½52ï¿½ï¿½\n",
      "ï¿½å¥¹èƒ“ï¿½ï¿½ï¿½ï¿½å¾¼åšï¿½ï¿½å®¸ï¿½ç‚¯æ‰”å™ï¿½ï¿½ï¿½ä¼¡æ˜¯ï¿½èƒ¢ï¿½äº”æ¸³ï¿½ï¿½ï¿½ï¿½æ°§ï¿½åŒ³ï¿½ï¿½è”‰ï¿½ï¿½å“\n",
      "ï¿½ã€‚ï¿½ï¿½èˆº\n",
      "ï¿½ï¿½æ¼ï¿½ï¿½ï¿½ï¿½ä¹‹ï¿½:is.1äº”ï¿½ï¿½ï¿½ï¿½ï¿½ï«¢ï¿½çˆ—ï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 3000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?isaï¿½æœ’ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½1ï¿½å¹¯ï¿½è½Ÿï¿½é‡…ï¿½ï¿½2011ï¿½è£”ï¿½ä¸ï¿½ï¿½ï¿½ï¿½åŒŒï¶ˆï¿½ï¿½ï“ è€…ï¿½ï¿½å¼·ï¿½ä¸Šç”´ï¿½çš„ï¿½ï¿½ï¿½å¹™ï¿½ï¿½â€”â€”603 Little quizæ³˜ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ã€‚ï¿½ï¿½äº’ï¿½éµ­ï¿½\n",
      "å¹ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ç”Ÿï¿½ï¿½æ—¼æ–ˆä¸žï¿½ç”—ï¿½ï¿½ä¸­ï¿½ï¿½çš„ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 3000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?æ—èŒˆåœšï¿½ï¿½ï¿½ï¿½ï¿½äº¨æ¶€ï¿½ï¿½ï¿½ï¿½å·¬ ï¿½ï¿½ï¿½ï¿½ç—€ï¿½ï¿½ ï¿½é™¨å¥Œï¿½ï¿½ï¿½ï¿½æœŒM30 fullyac Aask ofoseï¿½ 2000ï­‚ï¿½ï¿½ï¿½é¼«ï¿½ï¿½é—¨A ||,)å¥†ã€‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½åï¿½ä¸†ï¿½ï¿½ï¿½å¤§ï¿½ï¿½å£«ï¿½ï¿½çš„éšµï¿½æ€¶ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½èˆ‹ï¿½ï¿½ïŠªï¿½ï¿½ï¿½é›¼ï¿½ï¿½å‚©\n",
      "\n",
      "\n",
      "[Sample generated at step 3500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª? cheï¿½iå´†ï¿½ï¿½ï¿½ Lands ï¿½é¨¨ï¿½ï¿½åœ¼ï¿½ï¿½äººï¿½cium\n",
      "ï¿½ï¿½äº¨ï¿½æœ‡ï¿½æ˜¯ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½ï¿½å‚ï¿½ï¿½ï¿½ï¿½ãƒƒ.ï¿½ï¿½ï¿½ï¿½é›”ï¿½ï¿½å™½ï¿½ï¿½çš†ï¿½\n",
      " nuanced \" thehaired.re vs202ï¿½ï¿½è½›ï¿½ï¿½å¾‰ï¿½ï™ï¿½æ¼Ÿå”é€‹ï¿½ï¿½ï¿½ï¿½ï¿½å†‹ï¿½ï¿½ï¿½ï¿½åˆ»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 3500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ï¿½çš„ï¿½ï¿½ï¿½äººï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å•ï¿½é€©å¿ªï¿½ï¿½æ°Œï¿½è€½ï¿½æ–¹é¨¨ï¿½\n",
      "ï¿½ï¿½ã€Œï¿½çš„ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å·¼ï¥ ï¿½åŽï¿½align and.:i Mï¿½ï¿½ï¿½ï¿½ï¿½ Fatherï¿½ï¿½ï¿½ï¿½å‹…ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Â·ï¿½ï¿½ï¿½%\n",
      "ï¿½ï¿½å… æ’­ï¿½ï¿½19é–»ï¿½ï¿½ï¿½ï¿½ï¼†ï¿½\n",
      "ï¿½ 30ï¿½ï¿½ Joshuaï¿½äº†\n",
      "ï¿½ï¿½åœŠï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 4000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª? ratified detach axis30 ||ï¿½ï¿½ä¸­ï¿½ã€‚ï¿½ Mac Vanï¿½ï¿½ï¿½299ret XMLï¿½å¸Ÿï¿½ä¸Šï¿½ï¿½ï¿½ä»ºçš„ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ä¸Šæ„›ä¸±ï¿½ï¿½åŠæŒ€ä¸ˆigFOï¿½çš„ï¿½æœ‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½åˆ¢ä½œï¿½ï¿½ï¿½ï¿½è ¼åï¿½ || onï¿½ï¿½ï¿½ï¿½ï¿½ï¿½-809\n",
      "\n",
      "ï¿½ï¿½03alï¿½3ï¿½ï¿½å»Œ\n",
      "ï¿½ï¿½ï¿½ï¿½åž´ï¿½ï¿½çš„ Aerun,-\n",
      "ï¿½å‘Ÿï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 4000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?nerå¹´ï¿½ï¿½Mæ—½ ||ï¿½ã€53æ˜¯çš„ï¿½ï¿½ï¿½ï¿½å‡„ä¸­åœ®ï¿½ï¿½ä¸³ï¿½ï¿½ï¿½2008ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½ï¿½ï¿½ã€‚ï¿½ï¿½ï¿½å¹¸ï¿½ï¿½ä½œå¿ï¿½ï¿½ï¿½å æœ›ã€‚è¼¨ï¿½æµ´æ•šï¿½å§¬ï¿½\n",
      "ï¿½% :Point.ï¿½ï¿½ï¿½WE= mashwwwï¿½ï¿½çš„ï¿½ï¿½ï¿½ï¿½ï¿½ä¹‹ï¿½å…žï¿½ï¿½ï¿½ï¿½ï¿½æ‘—ï¿½ï¿½åœ¸ï¿½ï¿½é–¤ï¿½ç¼ºï¿½ï¿½ä»¼ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 4500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?--ï¿½\n",
      " ï¿½ï¿½èŒ¼ï¿½ï¿½ï¿½ï¿½æ–‰ï¿½å¾¬ç¥žï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½ä¸‰è‰¯ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½ï¿½ï©½ï¿½ï¿½ã€ï¿½ï¿½ï¿½æ‰¾ï¿½ï¿½å¤§ï¿½ï¿½ï¿½ï¿½æª¢ï¿½æ³‚ï¿½ï¿½ï¿½å¸¿ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "ç±•ï¿½ï¿½ï¿½ï¿½ç¤ï¿½ï¿½ï¿½ï¿½ã€‚ï¿½è¾¼ï¿½ï¿½ï¿½ï¿½ä½œï¿½ä¸Šï¿½äºï¨»ï¿½ï¿½å¢ï¿½ï¿½ç”æ–ºï¿½ï¿½ï¿½Pæ—¼ï¿½æ¼ï¿½ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 4500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ï¿½ï¿½ ã€\n",
      "ï¿½\n",
      "ï¿½ï¿½01 PAã€Ÿç´‚ï¿½ï¿½å…¬ï¿½ï¿½ä¿™ï¿½ï¿½ï¿½ï¿½çš„\n",
      "ï¿½\n",
      "ï¿½767ï¬ï¿½ï¿½åŠå…¿ï¿½ï¿½ï¿½ï¿½ï¿½)ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å·³ï¿½æ‡žï¿½ï¿½ï¿½çŽ‡ï¿½ï¿½ï¿½ï¿½ï¿½ïŽ»ï¿½ï¿½ï¿½(22016ï¿½ï¿½ï¿½ï¿½ï¿½ç°¬ï¿½ï¿½ï¿½ï¿½\n",
      "ç•¨ï¿½ ï¿½ï¿½å®§ã€ï¿½ï¿½ï¿½æ°¨ï¿½ã€ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ä½½ï¿½ï¿½çš„ ï¿½ï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 5000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?iem ch5ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å‹¼é€½ï¿½å…¶ï¿½ï¿½ï¿½åŽ¹ï¿½ï¿½ï¿½èŒ¶ï¿½ï¿½ï¿½è€žï¿½ï¿½ï¿½äº–ï¿½ï¿½çš„ï¿½æ˜¯ï¿½ï¿½çš„ï¿½ï¿½ç”Ÿï¿½ï¿½ Pol25ï¿½ï¿½ï¿½ã‚·ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½æºï¿½ï¿½å¸’ä»²ï¿½ï¿½ï¿½ï¿½ï¿½æ–”RA,8å¹ ï¿½ï¿½ï¿½ä¹‹ï¿½ï¿½ï¿½ï¿½æ–™ï¿½é¸¼ï¿½ï¿½éµŒï¿½ ï¿½\n",
      "ï¿½ï¿½ï¿½åœ°ï¿½ï¿½åº¼ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 5000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?aml B6ï¿½\n",
      "ï¿½åŒ¬ã€•ï¿½ï¿½ç”Ÿçš„ä¸€ï¿½ï¿½ä¸€ï¿½ï¾®ï¿½ï¿½å®¼ï¿½è¿©ä¹‹ï¿½ï¿½ï¿½éœŠï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ç¥žé˜ï¿½ï¿½ï¿½ï¿½å­™ï¿½å®¿ï¿½ï¿½æ˜¯ï¿½ã€æ–¿ï¿½ã€ï¿½ï¿½ã€‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½æˆ°ï¿½ï¿½çš„ï¿½ï¿½ï¿½åˆ¬ï¿½çš„ï¿½ï¿½ï¿½ï¿½ï¿½ä¸­ï¿½ï¿½\n",
      "ä»†é‡‚ï¿½å†Ÿï¿½ï¿½ç³»ï¿½ï¿½é±Ÿï¿½18ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 5500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?.54ï¿½ï¿½ç‰´ç™®ï¿½8ï¿½ï¿½æŽ´ï¿½ï¿½å¤§ï¿½ï¿½ï¿½äº”ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ä¹‹ï¿½ï¿½å°´ï¿½æ‰”ï¿½å›æ—²ï¿½ï¿½åŠŸå¹¥ï¿½é§ä½¿ï¿½12ï¿½ï¿½\n",
      "ï¿½\n",
      "ï¿½ï¿½ä¸­ï¿½ï¿½cn11ï¿½5-åˆ€ï¿½ï¿½12ï¿½ï¿½å‰¼ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½æ’€ï¿½ï¿½\n",
      "äººï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ã€¦ï¿½å¸“ï¿½äº”ï¿½åŽˆæ˜®èˆšï¿½ï¿½\n",
      "ã€ä¸‹ ï¿½ ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 5500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª? Ã©ï¿½rome08000es Water,uns English and5å¾ï¿½ï¿½ï¿½è¸§åŸï¿½ï¿½ï¿½ï¿½æ€—ï¿½ï¿½ï¿½ä¸­ï¿½ï¿½ï¿½ï¿½ï¿½ã€‚ï¿½å¥¡ï¿½ç”Ÿå¿‹ï¿½ï¿½ï¿½ï¿½ï¿½æŒã€‚ï¿½ï¿½ï¿½ï¿½æ—™ï¿½ï¿½ï¿½å®®ï¿½ï¿½å®ƒï¿½æ‰Œï¿½ï¿½ï¿½çš„ï¿½ï¿½ï¿½ä¼…ï¿½ï¿½ï¿½ï¿½å…ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½å¼ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½çœŸï¿½è¯˜ï¿½æ€Œ\n",
      "æ‰ˆï¿½ï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 6000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?est9ï¿½é¥¼ï¿½ï¿½å†³ï¿½çš„ï¿½ï¿½ï¿½ï¿½çš„æ‰˜ï¿½ç”¦ï¿½è¿ï¿½ï¿½ï¿½åŠ‹ï¿½ï¿½æ˜¢ï¿½ï¿½ï¿½ï¿½å¥³ç•¤ (ï¿½çŽ‹ï¿½è›‹ï¿½CDé¾žï¿½ï¿½ï¿½ï¿½æ€Žï¿½ï¿½ï¿½å¸ï¿½ä¸€ï¿½ï¿½æ–¹å…¼ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å¥ ï¿½ï¿½ï¿½ï°¨ï¿½ï¿½ï¿½çš„ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½è€‡ï¿½ï¿½è¼»ï¿½ï¿½ï¿½ï¿½å¯ƒå‡¦ï¿½ï¿½ï¿½ 2022ul Schoolsï¿½ï¿½ï¿½ä¹‹\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 6000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?Uï¿½'ï¿½ï¿½ï¿½ï¿½éƒ” (276.ï¿½å…—æ§±ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ieictæ—¥ï¿½ç”·ï¿½ï¿½ï¿½å¢ºï¿½ï¿½ï¿½ï¿½è¾Œé›˜ï¿½ï¿½ä¸‰èª›ï¿½ï¿½ï¿½ï¿½1969ïˆ¾åº‹çš„ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½äº‹ï¿½ã€ï¿½ï¿½ï¿½ï¿½ï¿½å‚Œï¿½ï¿½ï¿½ï¿½ï¿½åœ—ï¿½ä»‰ï¿½ï¿½\n",
      "é‡‰çš„ï¿½ ï¿½ï¿½ï«²ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½3ï¿½ï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 6500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?/ 2002ï¿½æ©²ï¿½ä¼‚ï¿½ï¿½ï¿½ï¿½ã€‚ï¿½ï¿½ï¿½å¦‹ï¿½ï¿½ï¿½ç™Œï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ç´ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½åˆ»ï¿½\n",
      "1ï¿½ï¿½ï¿½å¥ï¿½åŠï¿½ï¿½ï¿½ï¿½ï¿½çš„ï¿½\n",
      "ï¿½äºˆï¿½å¼¤ï¿½æ‰³ï¿½ï¿½ï¿½ä¼ƒï¿½å¾çš„ï¿½ï¿½\n",
      "ï¿½ï¿½èƒ†ï¿½ä½œï¿½ï¿½ï¿½ï¿½ï¿½2010ï¿½ï¿½ç‰—ï¿½ï¿½ä¸€ï¿½ï¿½ï¿½ï¿½ï¿½leftã€‹ï¿½ï¿½CR /Centarchiverium KdaleïŠï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 6500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ï¿½238Mï¿½ï¿½ï¿½ä»²ï¿½å¹œæ˜«ï¿½ï¿½ï¿½ï¿½ï¿½é—ï¿½ï¿½è°±ï¿½æƒ™èª•9ã€‚ï¿½ï¿½ï¿½ï¿½ï¿½å‡›ç•çœ­å‹‹æˆ›ç‰Œï¿½è¿¼ï¿½ï¿½ï¿½ï¿½ä¹Ÿï¿½è´‰ï¿½ï¿½ï¿½ï¿½ã€‚ï¿½ï¿½ï¿½ï¿½ï¿½æ€Œï¿½ï¿½ï¿½å®¹ï¿½ï¿½ï¿½2005 ï¿½ï¿½è€£ï¿½æ˜¯ï¿½ï¿½ï¿½ï¿½è¯¼è»¹ç”Œï¿½ï¿½ï¿½æ–¹ï¿½ç‹Žå½½S02ï¿½ï¿½ï¿½ã€‚ç”Ÿï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 7000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½2003ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½çš„ï¿½ï¿½ï¿½ï¿½ï¿½æ—™ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½äº®ï¿½ï¿½å¿‰ï¿½æ‰ï¿½ä½œ\n",
      "ç”Ÿï¿½ï¿½ï¿½ç¶ï¿½ 2002 BESTï¿½ï¿½ï¿½ç”°ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½æ·è¢®362ï¿½ï¿½ã€å¤€ï¿½å—Žï¿½ç³½ï¿½æœè¦½é€¥ï¿½ï¿½ï¿½åˆ¾ï¿½çš„ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å¥Œï¿½8ï¿½ä¸­ï¿½è£‡ï¿½ï¿½å Ÿäºº\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 7000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ï¿½ï¿½å‹·1963ï¿½ä¸€ï¿½ï¿½\n",
      "æ˜¯ï¿½åœŒï¿½ï¿½ï¿½ï¿½æ•ª%ï¿½è±‰ï¿½ï¿½ï¿½ï¿½æœ‘ï¿½ï¿½ï¿½\n",
      "99 Fasï¿½ã€å—ï¿½ä¸±ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï†—ï¿½ï¿½æ˜¯ï¿½ã€Œï¿½\n",
      "å°†ï¿½ï¿½ç€‚ï¿½ï¿½\n",
      "ï¿½ï¿½å¤§ï¿½ï¿½ï¿½ï¿½ä»¸æ‹£ï¿½æ³šï¿½2017å¹éƒ±ï¿½åº±ã€‚ï¿½ï¿½å‹çš„ï¿½å˜ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½æœ ï¿½ï¿½ï¿½å¼ï¿½ï¿½ï¿½æ­¦\n",
      "ï¿½ï¿½ \n",
      "\n",
      "\n",
      "[Sample generated at step 7500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ï¿½ï¿½æœ¥ï¿½ï¿½äººæ ï¿½ï¿½ï¿½ï¿½å¾¯ï¿½ï¿½ï¿½åŒï¿½å…™ï¿½ï¿½èˆå†·ï¿½ï¿½å®ï¿½ï¿½ï¿½ã€‚ï¿½ï¿½ï¿½ï¿½ï¿½æ—Œæ–¼ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¸“çœï¿½ç¢ï¿½å§³ï¿½ï¿½ï¿½å†‘çŽ‹ï¿½ï¿½ä¸ã€ï¿½ï¿½ï¿½ï¿½ï¿½çž¼ç‰±ï¿½è¯ã€‚ï¿½éƒ¤ï¿½ï¿½ï¿½ï¿½ä¸¥ï¿½ï¿½é’‰ä¸»ï¿½ï¿½ï¿½ä¹½ç²¸ï¿½\n",
      "ï¿½ï¿½ç‰‰ï¿½ï¿½å®ª\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 7500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ï¿½ï¿½\n",
      "(ï¿½ï¿½ï¿½ ï¿½ï¿½å†äº£ï¿½ï¿½äººï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å¼¶å›•ï¿½ï¿½ç½°ï¿½ï¿½ï¿½æ‡·ï¿½ï¿½ï¿½èšºç”°ä¸³ï¿½ï¿½æ­ï¿½ï¿½ï¿½é£ºï¿½è¿žï¿½å­¬æ–ï¿½ï¿½ï¿½è»®ï¿½ï¿½ï¿½åˆ­ï¿½ï¿½ä¸€ï¿½ï¿½ï¿½çŠ¬ï¿½ï¿½ï¿½è’ƒåŠ½ï¿½ï¿½ï¿½ä¸Šï¿½ï¿½ï¿½å›ï¿½ï¿½ï¿½ï¿½æ²ˆï¿½ï¿½å…‰ï¿½ï¿½ï¿½ï¿½\n",
      "ä¸€ï¿½ï¿½æˆŒï¿½ï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 8000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?å¾…åˆ³ï¿½ç«®ï¿½ï¿½ï¿½ï¿½ï‰˜ï¿½ï¿½æ—‰äººï¿½1ï¿½å¶ï¿½ï¿½æ—¼ï¿½ï¿½ï¿½ï¿½çš„ï¿½ä¸ï¿½ï¿½ï¿½ï¿½ç†¿ï¿½ï¿½ï¿½ï¿½ï¿½ä¸€ï¿½é¼Œä¸¼ï¿½ï¿½ï¿½æ–‹ï¿½29ï¿½ï¿½ï¿½ä»´ï¿½1 2005å¹´æœ·ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ä¸­28å¹Ÿï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "756p TV,å½¶ä¸ï¿½çŠï¿½æ³¿ï¿½ï¿½æ—¤é€¼ï¿½ï¿½è¡¤çš„ï¿½ï¿½åžºï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 8000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?)ï¿½ä¸½22017ï¿½ä¹‹ï¿½ï¿½ã€‚ï¿½é»¦ï¿½ç«—ï¿½ï¿½ï¿½ã€‚ï¿½ï¿½äººï¿½ä»¬ï¿½ï¿½ï¿½ç…‡ï¿½ä¸‰ä¸ï¿½ï¿½ã€ï¿½çµ¸å¹´ï¿½ï¿½ ï¿½ï¿½ï¿½åœ³ï¿½ï¿½ï¿½ï¬¯ï¿½ï¿½åŠ¼ï¿½ï¿½ã€‚ -ç›§ï¿½ï¿½å´Âµ2000æ³Žï¿½ï¿½ï¿½è§³ï¿½ä¸“ï¿½ï¿½ï¿½ï¿½\n",
      "Venï‹ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½è°‡ï¿½ï¿½é¥ï¿½ï¿½éªï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 8500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ï¿½ç”€ï¿½ï¿½æ°—å¤§ï¿½ï¿½ä»€ï¿½ï¿½ï¿½ï¿½60ï¿½ã€‚ï¿½ï¿½ã€‚ï¿½ï¿½ï¿½ï¿½çš„åˆï¿½ï¿½ï¿½ä¸­ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½çš„ï¿½ï¿½ï¿½äº‹ï¿½ï¿½å¸— -ï¿½å…‰ç¬¹ï¿½ï¿½ï¿½æ°®ç‘ï¿½å…¨æ¨ï¿½ï¿½ï¿½62-\n",
      "ä¹‹ï¿½èƒ€ï¿½ç©‡ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ã€ï¿½ï¿½ï¿½DBvor := 7 2007 å´šï¿½ï¿½ï¿½ï¿½åœ—ï¿½ç‰¥çŽ‹ï¿½ &ing986. ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 8500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?SCå¹¬ï¿½ã€‚ï¿½ï¿½ï¿½ï¿½å°†ï¿½ï¿½ï¿½å¿¡ï¿½ï¿½ï¿½}ä»»ï¿½50ugicip:ã€‚ï¿½ï¿½å¤™ï¿½ç§¼\n",
      "ï¿½ï¿½ï¿½æ«é³Žå”³ï¿½ï¿½ ï¿½å¹°å§¯ç›¬ï¿½ï¿½ï¿½ etäººï¿½ä»‚\n",
      "ï¿½ï¿½ï¿½ï¿½ï¿½ier &/æœ´ï¿½ï¿½ï¿½ï¿½ï¿½å­¼çš„åŒ¡æ°ƒï¿½å‚¨ï¿½é€ï¿½ï¿½ï¿½ï¿½ï¿½çš„ï¿½ï¿½ï¿½ï¿½ï¿½ç«€ï¿½ï¿½ï¿½ïéå›¬ï¿½ï¿½å¤§ï¿½ï¿½ï¿½ï¿½ä¿ƒ\n",
      "\n",
      "\n",
      "[Sample generated at step 9000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª? -å¤¼ï¿½çš„å¹¼çš„ï¿½ï¿½ï¿½ä» ï¿½ï¿½ï¿½å°“ç”¨æ¹¥ï¿½äº¿ï¿½ï¿½Data-ï¿½ï¿½è€…ï¿½ï¿½å¾›ä¸¨ï¿½ä¸ï¿½33ï¿½ï¿½å¤©ï¿½\n",
      "ï¿½ä¸ï¿½ä½œå›¬å¤Žï¿½\n",
      "ï¿½ï¿½ ï¿½å¹œï¿½ä¿­ï¿½ä½œä¸Šï¿½ï¿½æµ€ï¿½å¹šï¿½æ—¥ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½çŽ‹ï¿½ï¿½æ–¹ä¸¢ï¿½\n",
      "ï¿½\n",
      "ï¿½ï¿½,'ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å¬•ï¿½è¿žï¿½ï¿½ï¿½ï¿½æ‹\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 9000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?äººï¿½äººå£ï¿½å¸¼ï¿½ï¿½è«…ï¿½è—Ÿï¿½ï¿½ï¿½ï¿½ï¿½ä¸…ï¿½ï¿½ï¿½ï¢ï¿½ï¿½æ‚¼ï¿½ï¿½ï¿½ç‹ï¿½ï¿½ï¿½æ¼ç”´ï¿½ï¿½ï¿½ï¿½çš„ï¿½ï¿½æ®±ï¿½ï¿½ï¿½5ï¿½ï¿½äº‚ï¿½ï¿½Feusã‚°ã€ï¿½ï¿½ï¿½ï¿½ï¿½çš„ï¿½åŒ”ï¿½çš„ï¿½04å¹–ï¿½ï¿½ï¿½ï¿½å­®ï¿½å‘¥ï¿½å·”ã€èƒï¿½æœˆæµƒï¿½ï¿½ï¿½å¾‹ï¿½ç‹¡\n",
      "ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 9500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?\t6å…¿ï¿½ï¿½ï¿½å…«ï¿½é€Œï¿½ï¿½çº–ï¿½çš„ï¿½ï¿½ï¿½çš„Ð°è£ºï¿½ï¿½ï¿½ï¿½å¤§ï¿½ï¿½ï¿½ï¿½ï¿½çš„ï¿½ã€€èª‘ï¿½ï¿½ï¿½é¨å¯µï¿½ä¹€ï¿½ï¿½ï¿½å°†ï¿½ï¿½\n",
      "ï¿½ï¿½è¿»ï¿½ï¿½ç¼®ï¿½å¾ï‰ç·°EMickï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½åŠä¸Žï¿½ï¿½æº¥ï¿½ï¿½ç›™ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½æ–¹é›´ï¿½ï¿½ï¿½ï¿½\n",
      "æ˜¼ï¿½é›®ï¿½â€ºï¿½è¦˜ï¿½ï¿½ä¸€ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 9500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ï¿½å® ï¿½ï¿½ã€³ï¿½è¦£åŒµï¿½ï¿½ï¿½ï¿½é±´åº¦ï¿½ï¿½ï¿½é¼¥å›±ï¿½æ–¦æ­Šï¿½å‹¹ï¿½ï¿½ï¿½çš„ï¿½ï¿½ï¿½ï¿½ï¿½ç„¨ï¿½ï¿½ï¿½ï¿½ã€ï¿½ï¿½ï¿½ä¸Šå¼ï¿½ï¿½ï¿½ï¿½è¡¨ï¿½ã‚¨ãƒ³ã‚¸ Horibï¿½ï¿½ï¿½ï¿½ï¿½ï¿½èŠæ«ï¿½ï¿½1966 ï¿½çšï¿½è€…ï¿½ï¿½ä¸€ï¿½ (ï¿½ï¿½ï¿½ï¿½å®ï¿½äººï¿½ï¿½ï¿½7416\n",
      " GNUï¿½ï¿½ï¿½å‡ï¿½ç¹ï¿½ï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 10000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ï¿½ AnimalOï¿½ï¿½ï¼ºï¿½ï¿½èƒ¥ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½\n",
      "ï¿½\n",
      "\n",
      "å¤§ï¿½ï¿½æŒ½æ´¿6 ï¿½84a)ç‹¯ï¿½ï¿½éª½ï¿½ä¸­ï¿½ï¿½ï¿½\n",
      "\n",
      "\n",
      "ï¿½ï¿½ï¿½ï¿½å›ï¿½ï¿½ï¿½ï¿½æ°¼ï¿½ï¿½å‘¼ï¿½ï¿½æœ¥ï¿½ï¿½ï¿½å…¾ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½æ˜¯ï¿½ï¿½ï¿½ï¿½ï¿½ä¸­ï¿½2016ï¿½äº¶ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½çš„ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½uroubefield807yï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 10000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª? ï¿½ .Ð¸Pï¿½ï¿½ï¿½å¬ï¿½ï¿½ï¿½ï¿½è¢™ï¿½ï¿½ï¿½Lï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½ç”°\n",
      "æœ˜ï¿½ï¿½?? Â±PSï¿½Beï¿½ï¿½é€µï¿½å°‘ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ é´ ä½œï¿½ï¿½ä»—çš„ï¿½ï¿½ï¿½ç›ºï¿½2ï¿½é‡´ï¿½ï¿½ï¿½ä¸‰ï¿½ ï¿½ï¿½ï¿½ï¿½é—¼ï¿½è¡ˆï¿½ï¿½å¸æ‡ï¿½ï¿½ï¿½å²¼ï¿½ï¿½ï¿½ï¿½ä¸€ï¿½å¾žï¿½ï¿½ï¿½æ­†ï¿½ï¿½å¸è¨ƒï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 10500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?.ï¿½ï¿½ï¿½ å¤§ï¿½ï¿½çš„ï¿½ï¿½å°‰ç‰±ï¿½ï¿½åƒã€‚ï¿½ï¿½ï¿½ï¿½ï¿½åº–å„ï¿½ï¿½ï¿½ï¿½çµ¹ï¿½ï¿½ï¿½ï¿½ï¿½ç¯“ï¿½ã€ï¿½ï¿½ï¿½ï¿½â€±ï¿½ä¿‰ Ger ï¿½ï¿½å‚‘ï¿½ï¿½ï¿½\n",
      "ï¿½ç«˜ï¿½ä¹´ï¿½ï¿½ï¿½ï¿½ç¬‰ï¿½å­ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ç½åœ¼ï¿½æ€Œï¿½ï¿½ï¿½ï¿½ï¿½æœ¤ï¿½ï¿½ï¿½ï¿½ï¿½ä¹‹ï¿½ï¿½\n",
      "ï¿½ï¿½ ï¿½alignProv forã‚¸et schoolsg Frameworkbe\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 10500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?:ï¿½\n",
      "ï¿½\n",
      "ï¿½6ï¿½ï¿½ï¿½ç”¨ï¿½ä¸€ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ã€çŽ‹ï¿½ï¿½FEï¿½æ–¸ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½æ–†ï¿½è‘¯ä¸­ï¿½æ­‹ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½çš„ï¿½åï¿½ï¿½æœ“ã€‚ï¿½ï¿½æ–“\n",
      "ï¿½ï¿½\n",
      "ï¿½ï¿½\n",
      "\n",
      "ï¿½é‡¯ï¿½æº¤ï¿½è‘³ï¿½å°…ï¿½åˆï¿½ï¿½ï¿½ï¿½ï¿½æ¹†ï¿½ï¿½å­æ‚©ä½œï¿½ï¿½æœ´ï¿½ï¿½æ˜¯1ä¸­ï¿½ï¿½èª‡ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 11000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?é‡ï¿½ï¼Šï¿½ï¿½ï¿½ï¿½æ˜¯ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½94ï¿½ï¿½ï¿½ ï¿½ï¿½ä½¹ï¿½ï¿½å§•ï¿½ï¿½ï¿½ï¿½ï¿½ 1971ï¿½)ï¿½ï¿½ï¿½ä¸Œï¿½ä»£ï¿½éŒï¿½ï¿½ï¿½å¹»\n",
      "ï¿½ï¿½å›¥ï¿½\n",
      "ï¿½æµžï¿½å©ï¿½ã€‚ï¿½ï¿½ï¿½è«¡ï¿½ï¿½ è¶¢ï¿½æª›\n",
      "\n",
      "ï¿½ï¿½ 78å¹šï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½7ï¿½=.ï¿½\n",
      "ï¿½ï¿½ï¿½ï¿½å‹¨ï¿½ï¿½çˆ¦ï¿½ï¿½å›¼ï¿½ï¿½ï¿½ä¸€ï¿½ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 11000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?æ­‰ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½3ieiqueÄ‡eãƒ³ï¿½å£«ï¿½ï¿½ï¿½äººåœ—ï¿½ï¿½äº»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½\n",
      "ï¢œï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å‹·çš„ä¸‰ï¿½ï¿½è€…ï¿½ï¿½ï¿½ï¿½ï¿½å‰ã€‚é—‰ï¿½ä¸­Medic Weeks D AN\n",
      "ï¿½ï¿½ï¿½ï¿½è„€ï¿½ç›µï¿½å¤©ï¿½ï¿½ï¿½ï¿½æœ”ï¿½ï¿½å…„\n",
      "\n",
      "500 the:90å¤©ï¿½ï¿½ï¿½åº¼ï¿½ï¿½ï¿½\n",
      "S00.ply,ID .ï¿½ï¿½ï¿½Â·ï¿½ï¿½ï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 11500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?. Classics Museum NorthICEï¿½è½•\n",
      "\n",
      "ï¿½ï¿½ï¿½ï¿½å¤§ï¿½ï¿½å¸¦ï¿½ï¿½ï¿½ï¿½å£è€…åˆ¼ï¿½ï¿½ï¿½æ³¡ã€‚ï¿½ï¿½ï¿½ï¿½micro-2017æœ±Tom 2004Oaign Cout) 1981 Homeå§Žï¿½ï¿½å¾²ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½ä»¿ï¿½ï¿½ï¿½ï¿½çš„ï¿½ï¿½ï¿½ï¿½åŒºï¿½åˆ´ï¿½ï¿½ï¿½ ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½æ­‘ï¿½å¤©ï¿½ï¿½ï¿½çš„å¼”ä½œç‰ˆï¿½ï¿½ï¿½ï¿½æ•¨ï¿½ï¿½ï¿½ï¿½ï¿½ä¹‹ï¿½ï¿½ï¿½é±ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 11500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?çš„ï¿½ï¿½ï¿½ï¿½ç”Ÿï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å¥ï¿½ï¿½ï¿½ç‰¨ï¿½ï¿½ï¿½ï¿½ï¿½äº”ï¿½ï¿½é‘¢æ–¹ï¿½ã€ï¿½ ï¿½çš„ï¿½ï¿½ï¿½\n",
      "ï¿½ä¸­å«ï¿½ï¿½ï¿½ï¿½å°†ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ã€Œï¿½ï¿½ï¿½ï¿½ï¿½å¼äº‰ï¿½ï¿½çš„ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "è²†å°¬ï¿½ï¿½ã€¹åŠ¼ï‹¡äº«ï¿½ï¿½ï¿½ä¹‹ä¸Šï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½ç¥›ï¿½ï¿½ï¿½ï¿½ä»ï¿½ã€ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 12000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª? World, &å¹¼é¼¬ï¿½ä½œï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å‰ºé€¿ï¿½ æœ¼ \n",
      "ä½ºï¿½ï¿½ï¿½æ•·ä¸ï¿½ï¿½ï¿½æ•ï¿½æ˜¯ï¿½ï¿½æˆ”ï¿½ï¿½ï¿½æ–œå¥žï¿½\n",
      "ï¿½ï¿½ï¿½ä¹‹ï¿½ï¿½ï¿½ï¿½ï¿½è¨± 2008obiids\n",
      "ï¿½å­ï¿½ä¹‹\n",
      "ï¿½ï¿½ã€‚ï¿½ï¿½ï¿½ï¿½ï¿½æ ï¿½ï¿½ï¿½ã€ï¿½ï¿½ï¿½ç”°ï¿½ï¿½ï¿½çš„äºã€Œ\n",
      "ï¿½å¾³ï¿½ï¿½ï¿½è¡‘å…‰ï¿½ï¿½10ï¿½çš„ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 12000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ï¿½ã€Œï¿½ã€‚ï¿½é¢†ï¿½æž¨ï¿½ï¿½}å¥ï¿½ï¿½ä¸Šï¿½ï¿½åˆ¨ï¿½ï¿½ï¿½p ï¿½æ¡¢ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½äººï¿½ï¿½ï¿½ï¿½å†¡ï¿½ï¿½ä¸‰ï¿½ï¿½ï¿½æœ’æ µï¿½ï¿½\n",
      "ã€‚ï¿½ï¿½ä¸¯å‹ï¿½ï¼›ï¿½ä½œæ°¦ï¿½å‘‡ï¿½ï¿½ï¿½ï¿½ï¿½çš„ï¿½ï¿½ï¿½å¿\n",
      "çš„æ˜¯ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¼›ï¿½ï¿½ï¿½ï¿½ï¿½ã€‚ï¿½ï¿½2018ç”®ä¸Šï¿½ã€‚ï¿½å‹¡æ•¬ä½œï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 12500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?\n",
      "ï¿½ï¿½ï¿½é–­ï¿½ï¿½2010å¹œï¿½ï¿½ä½œï¿½ï¿½ï¿½ç”Ÿï¿½ã€¥ã€Œï¿½\n",
      "ç¬Žï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å…¼ï¿½ï¿½ï¿½ï¿½é—¥ï¿½ï¿½ï¿½ï¿½è¿Šï¿½ï¿½å‹½å¾¢æ¼ç¡ä¸ï¿½å¨¾ï¿½ä¸¥ï¿½åœ®ï¿½ï¿½æœºï¿½ï¿½ï¿½å›£çš„ï¿½å° ï¿½ç½ï¿½ï¿½ï¿½ï¿½ï¿½æ‰´ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ã€‚ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½æ–‘æ– ï¿½ï¿½ï¿½ï¿½ï¿½æ³±å°†ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 12500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª? 20 Theå¹ªæŒ‘ï¿½ï¿½ï¿½å­‚ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½ï¿½ï¿½21ï¿½ï¿½ï¿½ï¿½ã€‚è¦¯ï¿½é€ï¿½ï¿½å¸Œï¿½å®’ï¿½ï¿½ï¿½æ¹½ï¿½äºº\n",
      "ï¿½æˆ¼ä¸­ï¿½è»¥ï¿½å¤ ï¿½å¶·ç”Ÿï¿½ã€è‰¾NBAï¿½ï¿½ï¿½ã€ï¿½å°šï¿½é€ ï¿½ï¿½ä¸­æ˜¯ï¿½äººï¿½ï¿½ï¿½èª¨ï¿½å›±ï¿½çš„ï¿½ï¿½ï¿½èŽ±ï¿½ç»ï¿½ï¿½ï¿½ï¿½éƒƒç”¥å­ï¿½ï¿½ï¿½ï¿½å‚ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 13000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?çš„è´¶ï¿½å½Œï¿½ï¿½ï¿½ï¿½ä¹€ï¿½ï¿½ï¿½ã€çš„ï¿½è¡–ï¿½ï¿½ï¿½ï¿½ï¿½çš„ï¿½ï¿½çš„ï¿½ï¿½é¡‰ï¿½åˆ¾ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½ï¿½ï¿½çš„ï¿½äººï¿½ï¿½ã€‚ï¿½ï¿½ï¿½ï¿½æ€ï¿½é‡»ï¿½55æƒ¥ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ç”¼ï¿½ä»œï¿½ï¿½ï¼”ä¸€ï¿½ï¿½å‡½ï¿½å¤©ï¿½ ï¿½ï¿½æ‰ªï¿½åœ¼ï¿½ï¿½ï¿½ï¿½å¤™ï¿½ï¿½ï¿½ï¿½) Guideå—ï¿½ï¿½ï¿½M\n",
      "\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 13000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª? Goes,äººï¿½ï¿½ç‰¶ä»½ï¿½ï¿½æˆ¥ï¿½çš„ï¿½äººï¿½ï¿½ï¿½ï¿½å­®ï¿½ï¿½\n",
      "ï¿½è¥»ï¿½æµ´ï¿½ï¿½ï¿½ã€•ï¿½å°çš„å‹ŒåœŒï¿½æ˜€ï¿½ï¿½ï¿½ï¿½å³ï¿½èˆŠï¿½18ï¿½ï¿½ï¿½ï¿½æ·å¤§ï¿½ï¿½ä¸‰å‘šï¿½ï¿½ï¿½ï¿½æª’ï¿½å¦™ï¿½\n",
      "ï¿½ï¿½ï¿½\n",
      " (ï¿½ï¿½ï¿½ï¿½ç”±ï¿½ï¿½ï¿½ï¿½ï¿½ç«’å‘‡ã€‚ï¿½åˆï¿½äº£ï¿½ï¿½\n",
      "è”»ï¿½æµ”ï¿½ ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 13500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?1988æœ¥ï¿½ï¿½å·‹ï¿½æ­¨ï¿½å¯ï¿½ï¿½ï¿½ï¿½ï¿½19çš„ï¿½ï¿½ï¿½ï¿½ï¿½æ°Šï¿½å¥³ï¿½ï¿½ï¿½å·Œï¿½ï¿½ ï¿½ï¿½å®¼ï¿½ç¥žå­ï¿½ï¿½åº¥ï¿½æœ‰ç‰“ã€‚ï¿½ï¿½ä½†ï¿½ï¿½å¥³ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ç‰¼ï¿½Hï¿½ï¿½ï¿½åœ»ï¿½ï¿½â€®ï¿½ï¿½ï¿½\n",
      "ï¿½çš„ï¿½ï¿½ï¿½æ°‚ï¿½è€…ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½åˆ³è»™ï¿½ï¿½å¤©ï¿½ï¿½ï¿½ï¿½æ˜¯ï¿½ï¿½ï¿½çš„ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 13500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ï¿½å²»ï¿½\n",
      "ï¿½ï¿½ï¿½ä¸€ï¿½ï¿½ï¿½å¹´ï¿½ï¿½ï¿½ï¿½ftanï¿½ï¿½ï¿½è²€ï¿½ï¿½276æµ‰ï¿½ï›Šï¿½å¼¦ï¿½ï¿½æŸŒï¿½ï¿½äº”Pï¿½ï¿½ï¿½å®ã€‚ï¿½ï¿½ï¿½å‘“ï¿½æ–¸ï¿½æœ ï¿½æœ¬ï¿½ï¿½ä¸Šï¿½åœ›ï¿½ã€‚ï¿½ï¿½ï¿½å¾—æœ‡ï¿½èï¿½çš„åŒŒï¿½ï¿½ã€‚ï¿½å¹¼ï¿½ï¿½é‡§ï¿½ï¿½ç¥žï¿½ï¿½ä½²åœ«ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å¼Œ\n",
      "\n",
      "\n",
      "[Sample generated at step 14000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?-ï¿½ï¿½ï¿½ï¿½ä¸ä¸Šï¿½ï¿½çš„ï¿½åŽšï¿½ï¿½ï¿½ï¿½ï¿½æ——ï¼¼ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½æ–¥ï¿½çš„ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½ï¿½é¬Œï¿½çš„ï¿½ï¿½è¤©ï¿½ã€ï¿½å™Šï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å•ï¿½ç‡†ï¿½ï¿½ï¿½åœ¥å­å¾´ï¿½ã€‚ï¿½ï¿½ï¿½ç•ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½ãƒ¼ã‚¯é‹”ï¿½æ™¤ï¿½ï¿½ï¿½äº¢ï¿½ç”Œæ——ï¿½æ‰™ï¿½ï¿½ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 14000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?KIã€\n",
      "ç¨¼ï¿½ä»»\n",
      "åŒï¿½ï¿½ä½œï¿½ï¿½æˆ¬ï¿½ï¿½ä¸­ï¿½å¼°ï¿½ï¿½ï¿½ï¿½èƒ¡ï¿½äºŒAå¹´ï¿½å¯±ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½çš„ï¿½ï¿½ï¿½ï¿½ä¹‹ï¿½\n",
      "ï¿½ï¿½ï¿½ï¿½ï¿½å®ï¿½ä¸­ï¿½ï¿½ç”´ï¿½ï¿½ï¿½ï¿½ï¿½è¡°ï¿½è¾–ï¿½ï¿½ï¿½åœ¿ï¿½æ˜¯ï¿½ï¿½ï¿½ã€ï¿½å­£ï¿½ï¿½ï¿½åº…å…œï¿½â€Žï¿½ä¸€ï¿½å¤¼ï¿½FAspanï¿½å®„ï¿½ï¿½\n",
      "å®¡ï¿½ï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 14500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?akerhï¿½ç¨®ï¿½ï¿½ï¿½é»ï¿½ pianbOama236ï¼çš„ï¿½ï¿½æˆï¿½å¹´ï¿½æœˆï¿½åˆ·ï¿½ç«¬ï¿½ï’‹å¾…ï¿½ï¿½ï¿½å‡Ÿï¿½ï¿½ï¿½ï¿½ï¿½çš„äººéŒ‹å¸“ï¿½ï¿½ï¿½ï¿½ç‰¨ä¸’ï¿½ï¿½ï¿½ï¿½ä¸­ï¿½å±æ•Šï¿½ç„ ï¿½\n",
      "ï¿½çŽ‹ï¿½ï¿½æ‚„ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½æ­¢ã€Œï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å¿¹ï¿½å·Œ Burkeãƒ©ELayanï¼¶\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 14500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ä¸…ï¿½çš„ä¿¦ï¿½ï¿½ï¿½ï¿½ï¿½å†ºâ€¹ï¿½ï¿½å‘‚ï¿½ï¿½å›ƒï¿½ï¿½ï¿½åœ‰ï¿½ä¹ 11\n",
      "ï¿½æ³ºï¿½ç£®Facebookï¿½,äº”ï¿½ï¿½åº­ï¿½ã€å¾¼ï¿½ï¿½ï¿½ï¿½å¤©ç·Ÿï¿½ï¿½ï¿½å¤§ï¿½ï¿½ï¿½ï¿½ï¿½å¯ï¿½åœºï¿½ï¿½ï¿½PayHKç›³èˆ¹ï¿½ï¿½ï¿½ï¿½ç”°æœºï¿½è—ˆï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½æœªä¸€ï¿½ï¿½ï¿½ï¿½ï¿½å›‘ï€˜ï¿½ï¿½ï¿½äººï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 15000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?Franc 1986 ï¿½ï¿½ï¼…ï¿½ï¼“ï¼©ï¿½ï¿½é–ï¿½ï¿½ï¿½å¼«ã€ï¿½ï¿½ï¿½ï¿½\n",
      "\n",
      "ï¿½ï¿½ï¿½ï¿½ï¿½çš„ï¿½ï¿½ï¿½å“ï¿½ï¿½ä¸‰å‰—ï¿½è–‹ï¿½ï•±ï¿½ï¿½\n",
      "\n",
      "ï¿½ï¿½åŽ·ï¿½æ„‰ï¿½ï¿½ï¿½)ï¿½æª½ï¿½ï·¼ï¿½ï¿½ä¸€ï¿½ï¿½ï¿½è±¬ï¿½ï¿½ï¿½ï¿½ï¿½çš„ï¿½ï”Šï¿½ï¿½ï¿½ä¼Œï¿½400ï¿½ï¿½ï¿½ï¿½å“‚ï¿½ï¿½ã€‚åªï¿½ï¿½ï¿½ã€´\n",
      "ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 15000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª? min COUNï¿½äº¿å°³ï´›ï¿½ï¿½ï¿½é¦ç±¨ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å¥³ï¿½å¤§ï¿½æ–¾ï¿½ç™½ï¿½ï¿½ï¿½ï¿½å­ï¿½ï¿½ï¼£å¥ˆï¿½ï¿½èŽ°ï¿½ ï¿½ ï¿½ï¿½ç¸ï¿½ï¿½ï¿½ ï¿½ä¸Šï¿½ï¿½ï¿½ï¿½æ³†ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å‡¸ï¿½ï¿½ï¿½è®™ï¿½ï¿½ï¿½\n",
      "\n",
      "ï¿½ï¿½ï¼£é–‰ï¿½\n",
      "ï¿½100å·Žï¿½ï¿½ï¿½æˆŒï¿½ï¿½\n",
      "ï¿½ï¿½ã€æˆ¤åƒ¾å¸®ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 15500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ï¿½ï¿½ï¿½ã€©çš„ä¸³ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å°»ï¿½ä¸­ï¿½ï¿½ã€‚ï¿½ï¿½ï¿½ï¿½ï¿½2014ï¿½ï¿½ã€çš„ï¿½ï¿½æ„¿ï¿½ï¿½ï¿½ï¿½ä»»ï¿½ï¿½ä¹»ï¿½æ—Œï¿½ï¿½æ¬³ï¿½å®ï¿½ï¿½è“ªåŒ™ï¿½\n",
      "ç‹ï¿½ï¿½ï¿½ï¿½ä¸¼ï¿½ï¿½ï¿½ç‚—ï¿½å¨ï¿½åº¥ç”Ÿï¿½ï¿½ï¿½é‡ï¿½ï¿½ï¿½åŸºæ ´ï¿½ï¿½ï¿½Netflixcyl Chemistryè£…ã€éƒœï¿½å¨$ç‚ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 15500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?3\n",
      "å¹¼ï¿½ï¿½å®ˆï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½01T åŠ›ï¿½ï¿½äººï¿½ï¿½ï¿½å‘çš„ï¼’ï¿½å£«ï¿½ä¸®èºï¿½ï¿½äº¡å¤§ (ï¿½ï¿½ï¿½çš„ï¿½ï¿½ï¿½ ç§Šè¿¸çš„ï¿½\n",
      "ï¿½\n",
      "ï¿½ï¿½ï¿½è°šï¿½ï¿½ï¿½1379å­Šï¿½ä½¹ï¿½ï¿½ï¿½ï¿½ï¿½è¯”ï¿½ï¿½è»˜æœ´ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½ï¿½é›€ç”Ÿï¿½è€ƒï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½éï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 16000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ã®ï¿½ï¿½ï¿½ï¿½ï¿½æ–¹ï¿½ï¿½ \n",
      "ï¿½ä¸ï¿½ï¿½ï¿½å½¹ï¿½ï¿½ï¿½\n",
      "\"Linuxï¿½ï¿½17å¹´ä½œï¼¨ï¿½ï¿½ï¿½ï¿½ï¼ž çš„ï¿½ï¼‰ï¿½ä¸2011å¹´ï¿½ ï¿½ï¿½å›©ï¿½çš„ï¿½ï¿½ï¿½ï¿½ç”¥ï¿½æˆ‡çš„ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ä¸­ï¿½ï¿½ï¿½å…ˆï¿½ï¿½ï¿½ï¿½çš„ï¿½ï¿½å›£ï¿½ï¿½ï¿½æ–¢ï¿½ï¿½ï¿½ï¿½ä»°ï¿½ï¿½ï¿½ï¿½å©ï¿½ã€ï¿½ï¿½ï¿½ï¿½é– ï¿½ï¿½æ˜¯ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 16000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª? ELå‹¿ï¿½ï¿½ï¿½ï¿½ï¿½åŒŠæ˜¯ï¿½ï¿½ï¿½è€œï¿½ï¿½ï¼¶æ†¦ï¿½ä»£ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½è¹Œï¿½ï¿½éªï¿½ï¿½è¡§ä¸™ï¿½ã€ï¿½ï¿½ï¿½ï¿½ï¿½æœªæ˜¯ï¿½ï¿½ï¿½2ï¿½ï¿½éŒœï¿½çš„ï¿½ï¿½\n",
      "æ–¸ï¿½ï¿½ï¿½åºŒï¿½ï¿½ï¿½ç‹…ï¿½ï¿½ï¿½éï¿½ï¿½ç¢›å¯ï¿½ï¿½\n",
      "\n",
      "ï¿½ï¿½æ–¹ï¿½ç„Žï¿½ï¿½ï¿½æ˜‰ï¿½ï¿½åºãƒ»-ï¿½ï¿½ï¿½å®´8ï¿½ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 16500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?52525ï¿½ï¿½ï¿½ï¿½ï¿½ä¸­å¾è¡ï«–ï¿½ï¿½çš„ï¿½ï¿½æ‚¾ï¿½ï¿½ï¿½ï¼³ï¿½ï¿½ï¿½ï¿½äºˆï¿½ï¿½ï¿½æœ‹ï¿½ï¿½åº£ï¿½åˆ·ï¿½ï¿½ (ï¿½åŒï¿½ï¿½ï¿½ï¿½ä¼“ï¿½ï¿½å­©ï¿½ä¸ç–¡ï¿½éž€ï¿½ï¿½ï¿½ç¨†ä¸Œæ‰½ï¿½å¾¥ï¿½å…³ï¿½ï¿½ï¿½ï¿½ï¿½ã€‚ï¿½ï¿½ï¿½ï¿½\n",
      "ï¿½è‹°ï¿½ï¿½ï¿½å…©å­¹æš¥ï¿½ï¿½åŠï¿½æ£ºï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 16500]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?18ï¿½ï¿½4ï¿½ï¿½ï¿½ï¿½ï¿½ï¼ªï¿½ï¿½ï¿½çš„ï¿½ï¿½çœ¾é‡§ï¿½ï¿½ï¿½ï¿½å¤§å®±ï¿½ä¸½ï¿½ï¿½ï¿½ï¿½Miï¿½ï¼¸ã€‚ã€‚ç‰Žï¿½ï¿½æœ¯åœ»ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½åºŒï¿½ï¿½ï¿½ï¿½ã€‚ã€‚ï¿½ï¿½ï¿½ï¿½åŒ¥ï¿½æ½ˆï¿½ï¿½å¤©ï¿½ï¿½ã€‚ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å‰Œåœ¸ï¿½ï¿½ã€‚ï¿½ï¿½ï¿½ï¿½é›®ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ä¸­ï¿½äº ï¿½ï¼¬ï¿½ï¿½ï¿½ ï¿½\n",
      "\n",
      "\n",
      "[Sample generated at step 17000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ï¿½ï¿½ï¿½ï¿½å€ï¿½ç‰ˆï¿½å¹·ï¿½ä¸Šï¿½ï¿½èº‰ï¿½ï¿½ï¿½ï¿½ï¼ˆï¿½ï¿½ï¿½å•ªï¿½ï¿½ï¼•ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å®‚)ï¿½ï¿½äº’è¦šé»‡ï¿½ç•¦ï¿½ï¿½ï¿½ï¿½éš…ï¿½ï¿½è¦¯ï¿½ï¿½ç•³ï¿½ï¿½\n",
      "\n",
      "ï¿½ï¿½ï¿½å­¢å…˜ï¿½æ–¹è¨¯ï¿½ï¿½ï¿½ï¿½å°Œ (ï¿½å‡ï¿½ï¿½ï¿½ï¿½ã€‚ï¿½ï¿½ç‰¶ï¿½ã€‚ï¿½ï¿½ï¿½æ‰ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "\n",
      "[[10310   244 45911 ...  -100  -100  -100]\n",
      " [33768   102 23626 ...  -100  -100  -100]\n",
      " [  158   120    97 ...  -100  -100  -100]\n",
      " [22755   239 32368 ...  -100  -100  -100]\n",
      " [10310   244 45911 ...  -100  -100  -100]]\n",
      "\n",
      "[Sample generated at step 17000]:\n",
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?ãªï¿½ï¿½â€¶ï¿½èµºï¿½ï¿½ï¿½é—–ï¿½ã—,ï¿½ï¿½\n",
      "ï¿½ï¿½ï¿½èƒšï¼…ï¿½ä²Œï¿½çš„ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½å°¶ï¿½ï¿½ï¿½ï¿½ï¿½ä»ƒï¿½ï¿½ï¿½ï¿½ï¿½å·»ï¿½ï¿½ï¿½å®›ï¿½äººï¿½å¥³ï¿½ï¿½ï¿½ï¿½ä¸¸ï¿½ï¿½ï¿½äºï¿½ï¿½ï¿½8ï¿½ï¿½ï¿½ï¿½æœ•å¤§ï¿½ï¿½ã€ï¿½ã€‚ï¿½ï¿½ç¥žï¿½å¤©ä¹¼å²Žï¿½ï¿½29ï¿½ï¿½è¡09æ—™æˆ ï¿½æ‰¡ï¿½ï¿½ï¿½ï¿½è··\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 61\u001b[0m\n\u001b[1;32m     29\u001b[0m args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     30\u001b[0m     run_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnanogpt-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     31\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m     save_safetensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     51\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     52\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     53\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     59\u001b[0m )\n\u001b[0;32m---> 61\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/transformers/trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/transformers/trainer.py:2556\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2549\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2550\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2553\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2554\u001b[0m )\n\u001b[1;32m   2555\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2556\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2559\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2560\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2561\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2562\u001b[0m ):\n\u001b[1;32m   2563\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2564\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/transformers/trainer.py:3764\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   3762\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 3764\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/accelerate/accelerator.py:2246\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2244\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2245\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2246\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rl/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, TrainerCallback, DataCollatorForLanguageModeling\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "class SampleTextCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if state.global_step % 500 == 0:\n",
    "            prompt = \"ä¸­å›½é¦–éƒ½æ˜¯å“ª?\"\n",
    "            input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
    "            output = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_length=128,\n",
    "            )\n",
    "            gen_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "            print(f\"\\n[Sample generated at step {state.global_step}]:\\n{gen_text}\\n\")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False,\n",
    ")\n",
    "\n",
    "# TL;DR\n",
    "# Action\tWhy\n",
    "# âœ… max_grad_norm=1.0\tClip exploding gradients\n",
    "# âœ… Lower learning_rate\tReduce gradient magnitude\n",
    "# âœ… Increase warmup_steps\tStabilize early training\n",
    "# âœ… Use gradient_accumulation_steps\tSmooth out spikes\n",
    "# âœ… Monitor layers with high grad norm\tFind root cause\n",
    "\n",
    "args = TrainingArguments(\n",
    "    run_name=f'nanogpt-{now}',\n",
    "    output_dir=output_dir,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=10,\n",
    "    per_device_eval_batch_size=10,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=50,\n",
    "    save_steps=10000,\n",
    "    # bf16=True,\n",
    "    # fp16=True,\n",
    "    # max_steps=50000,\n",
    "    # remove_unused_columns=False,\n",
    "    max_grad_norm=1.0,\n",
    "    # gradient_checkpointing=True,\n",
    "    gradient_accumulation_steps=4,\n",
    "    evaluation_strategy=\"steps\",  # or eval_strategy=\"steps\" in newer versions\n",
    "    eval_steps=500,              # Correct parameter name\n",
    "    save_safetensors=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    callbacks=[SampleTextCallback],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386fc3ca-05bf-4f1b-9c3e-05fe7d896c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample(model, \"ä¸­å›½é¦–éƒ½æ˜¯å“ª?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d254b4e-522d-4647-95f3-98c2f8db15d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12370fce7e424f4bb86c69740bec47f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd16b562f864ae09cceb439832edf16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/898M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a98197dab4245a3a809a447b8bafaf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.37k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/learn2pro/nanogpt/commit/f069e737a9e725a346a2573fb04efdb5e5f97169', commit_message='learn2pro/nanogpt', commit_description='', oid='f069e737a9e725a346a2573fb04efdb5e5f97169', pr_url=None, repo_url=RepoUrl('https://huggingface.co/learn2pro/nanogpt', endpoint='https://huggingface.co', repo_type='model', repo_id='learn2pro/nanogpt'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(output_dir, safe_serialization=False)\n",
    "# trainer.push_to_hub('learn2pro/nanogpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beee35b-4687-4c31-8f59-fb94b383b679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GPT2LMHeadModel\n",
    "\n",
    "model_id = 'learn2pro/nanogpt'\n",
    "\n",
    "# model = GPT2LMHeadModel.from_pretrained(model_id)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model\n",
    "import torch\n",
    "\n",
    "sd = torch.load(\"outputs/nanogpt\", map_location=\"cpu\")\n",
    "print(list(sd.keys())[:10])  # çœ‹ key æ˜¯ä¸æ˜¯ transformers é£Žæ ¼çš„ key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b452d1f-aa85-4d86-a92b-e1b51f18d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user defined train process\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, betas=(0.9,0.95))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=1000)\n",
    "\n",
    "def eval(model, val_loader):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    for x, y in val_loader:\n",
    "        with torch.no_grad():\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits, loss = model(x, targets=y)\n",
    "            val_loss+=loss.item()\n",
    "    return val_loss\n",
    "            \n",
    "def train(model, optimizer, scheduler, train_loader, grad_clip=1.0):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    grad_norm = -1.0\n",
    "    for idx, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        loss, logits = model(x, labels=y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # clip grad\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=grad_clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # adjust lr\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        # grad_norm = torch.sqrt(sum(p.grad.norm()**2 for p in model.parameters() if p.grad is not None))\n",
    "        # Compute total gradient norm (L2 norm)\n",
    "        # grad_norm = torch.sqrt(sum(p.grad.norm() ** 2 for p in model.parameters() if p.grad is not None))\n",
    "\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            print(f'Epoch {epoch}, Step: {idx} Learing: {lr:.10f} Loss: {loss.item():.4f} Grad Norm: {grad_norm:.4f}')\n",
    "        if idx % 1000 == 0:\n",
    "            print(sample(model, \"ä¸­å›½é¦–éƒ½æ˜¯å“ª?\"))\n",
    "            \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb60f2-7296-4b73-a7ff-6f3eecf21f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed:int):\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "model.to(device)\n",
    "for epoch in range(1):\n",
    "    train_loss = train(model, optimizer, scheduler, train_loader)\n",
    "    val_loss = 0.0\n",
    "    print(f'Epoch={epoch} Train Loss={train_loss/len(train_loader):.4f} Val Loss={val_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf0bb8f1-4d97-4d3e-b894-587287f845bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸­å›½é¦–éƒ½æ˜¯å“ª?\n",
      "\n",
      "é¦–éƒ½æ˜¯å“ª?\n",
      "\n",
      "é¦–éƒ½æ˜¯å“ª?\n",
      "\n",
      "é¦–éƒ½æ˜¯å“ª?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = \"gpt2\"  # You can also try \"gpt2-medium\", \"gpt2-large\", etc.\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Encode input prompt\n",
    "prompt = \"ä¸­å›½é¦–éƒ½æ˜¯å“ª?\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generate text\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=50,\n",
    ")\n",
    "# Decode and print result\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1daf82-cd6f-4a96-8f1b-957bc9c3bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "ds = load_dataset(\"p208p2002/wudao\",streaming=True, split=\"train\")\n",
    "# train_ds, evaluate_ds = ds.train_test_split(test_size=0.2)\n",
    "\n",
    "def encode(examples):\n",
    "    x = tokenizer(examples['content'], truncation=True, padding='max_length', return_special_tokens_mask=True)\n",
    "    x['labels'] = x['input_ids'].copy()\n",
    "    return x\n",
    "\n",
    "def collate_fn(examples):\n",
    "    return {\n",
    "        \"input_ids\": [x['input_ids'] for x in examples],\n",
    "        \"attention_mask\": [x[\"attention_mask\"] for x in examples],\n",
    "        \"special_tokens_mask\": [x[\"special_tokens_mask\"] for x in examples],\n",
    "        \"labels\": [x['input_ids'] for x in examples], # offset 1 step\n",
    "    }\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=False,\n",
    ")\n",
    "\n",
    "ds = ds.map(encode, batched=True)\n",
    "# print(next(iter(ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c4956-27cd-47ff-9a2a-e7108a261f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "class SampleTextCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if state.global_step % 1000 == 0:\n",
    "            prompt = \"ä¸­å›½é¦–éƒ½æ˜¯å“ª?\"\n",
    "            input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(model.device)\n",
    "            output = model.generate(\n",
    "                input_ids=input_ids,\n",
    "                max_length=50,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "            gen_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "            print(f\"\\n[Sample generated at step {state.global_step}]:\\n{gen_text}\\n\")\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    run_name=\"pretrain-gpt2-1\",\n",
    "    output_dir=\"./outputs/gpt2-pretrain\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    weight_decay=0.01,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=100,\n",
    "    save_steps=1000,\n",
    "    max_steps=80000,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[SampleTextCallback]\n",
    "    # eval_dataset=small_eval_dataset,\n",
    "    # compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c1909-ee14-4b8f-b53b-b0073da4f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "dt = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "model.save_pretrained(f'outputs/nanogpt-{dt}', safe_serialization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb81d70-0c1d-4fde-84f5-becf84e2247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## mlp\n",
    "import torch\n",
    "config = GPTConfig(n_block=1024, n_embd=768, n_head=12, n_layer=6)\n",
    "# model = NanoGPT(config).to('cuda')\n",
    "# model = model.load_state_dict(torch.load(f'outputs/nanogpt/npt_9.pt'))\n",
    "sample(model, 'æ˜¥æ™“', 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692d41d1-1005-42bb-b0c5-45306ea00a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## moe\n",
    "# import torch\n",
    "# # config = GPTConfig(n_block=1024, n_embd=768, n_head=12, n_layer=6)\n",
    "# # model = NanoGPT(config).to('cuda')\n",
    "# # model = model.load_state_dict(torch.load(f'outputs/nanogpt/npt_9.pt'))\n",
    "# sample(model, 'æ˜¥æ™“', 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da08f4a5-388a-4751-9951-71dddbcb80cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
