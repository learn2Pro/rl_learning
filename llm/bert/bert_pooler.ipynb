{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tangyun/opt/miniconda3/envs/rl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer,BertModel,BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "text = 'this is a text sentence.'\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2023, 2003, 1037, 3793, 6251, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(text,return_tensors='pt')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'this', 'is', 'a', 'text', 'sentence', '.', '[SEP]']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. forward and pool output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['last_hidden_state', 'pooler_output'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    outputs\n",
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 768]), torch.Size([1, 768]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['last_hidden_state'].shape,outputs['pooler_output'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9320, -0.4660, -0.7054,  0.8013,  0.5395, -0.2326,  0.8985,  0.3100,\n",
       "         -0.5941, -1.0000, -0.1055,  0.8209,  0.9858,  0.2604,  0.9526, -0.6847,\n",
       "         -0.2648, -0.6366,  0.3471, -0.7114,  0.6518,  0.9998,  0.4752,  0.3604,\n",
       "          0.5276,  0.9401, -0.6821,  0.9463,  0.9627,  0.7596, -0.7972,  0.2211,\n",
       "         -0.9909, -0.2564, -0.7488, -0.9928,  0.4347, -0.8085, -0.0717, -0.0137,\n",
       "         -0.9286,  0.3592,  1.0000, -0.4739,  0.2884, -0.4205, -1.0000,  0.3234,\n",
       "         -0.9190,  0.7232,  0.6715,  0.5167,  0.2301,  0.5236,  0.5461, -0.0622,\n",
       "         -0.0630,  0.1883, -0.2802, -0.6607, -0.6670,  0.3900, -0.6133, -0.9413,\n",
       "          0.5821,  0.5472, -0.1604, -0.3769, -0.1576, -0.0250,  0.9041,  0.2955,\n",
       "         -0.0418, -0.8321,  0.3900,  0.3109, -0.6546,  1.0000, -0.5625, -0.9819,\n",
       "          0.6171,  0.5162,  0.6011,  0.0482,  0.2289, -1.0000,  0.5958, -0.2103,\n",
       "         -0.9917,  0.1602,  0.5617, -0.2821,  0.4634,  0.6287, -0.4933, -0.3350,\n",
       "         -0.4028, -0.5878, -0.2872, -0.2631,  0.1988, -0.3540, -0.3882, -0.4115,\n",
       "          0.3234, -0.5114, -0.5085,  0.4941, -0.0114,  0.7357,  0.4615, -0.4198,\n",
       "          0.4495, -0.9632,  0.6444, -0.4120, -0.9886, -0.6143, -0.9883,  0.7400,\n",
       "         -0.0702, -0.2572,  0.9748, -0.0086,  0.3666, -0.1545, -0.7035, -1.0000,\n",
       "         -0.4364, -0.4116, -0.1010, -0.2736, -0.9826, -0.9627,  0.7004,  0.9718,\n",
       "          0.2619,  0.9998, -0.3054,  0.9478, -0.1006, -0.4293,  0.0960, -0.5103,\n",
       "          0.6878,  0.4061, -0.7764,  0.2234, -0.0699,  0.2507, -0.5001, -0.3151,\n",
       "         -0.6120, -0.9422, -0.4599,  0.9538, -0.2553, -0.7623,  0.4071, -0.2945,\n",
       "         -0.3870,  0.8860,  0.6171,  0.4231, -0.2888,  0.5307,  0.2569,  0.5667,\n",
       "         -0.9075,  0.2098,  0.5000, -0.3142, -0.6503, -0.9822, -0.3632,  0.5577,\n",
       "          0.9902,  0.7836,  0.4002,  0.6218, -0.4148,  0.5758, -0.9572,  0.9842,\n",
       "         -0.2230,  0.3169, -0.1974,  0.3705, -0.9103,  0.0049,  0.8592, -0.4281,\n",
       "         -0.8949, -0.1139, -0.5668, -0.4746, -0.5588,  0.5546, -0.4232, -0.4242,\n",
       "         -0.1781,  0.9459,  0.9806,  0.7665, -0.1614,  0.5974, -0.9268, -0.5548,\n",
       "          0.1379,  0.3220,  0.1891,  0.9944, -0.5132, -0.2329, -0.9579, -0.9876,\n",
       "         -0.0068, -0.9122, -0.1263, -0.7131,  0.5984,  0.0540,  0.3312,  0.4399,\n",
       "         -0.9913, -0.8647,  0.3815, -0.4357,  0.4890, -0.3445,  0.8146,  0.8397,\n",
       "         -0.7184,  0.7613,  0.9425, -0.6402, -0.7862,  0.8809, -0.3388,  0.9255,\n",
       "         -0.6946,  0.9935,  0.7557,  0.7025, -0.9382, -0.5615, -0.9338, -0.4925,\n",
       "         -0.2236, -0.1925,  0.7047,  0.6824,  0.4130,  0.5055, -0.6258,  0.9983,\n",
       "         -0.8016, -0.9645, -0.0566, -0.1498, -0.9907,  0.7389,  0.2659, -0.0726,\n",
       "         -0.5518, -0.6016, -0.9692,  0.9009,  0.1575,  0.9914, -0.2993, -0.9344,\n",
       "         -0.6036, -0.9323, -0.1166, -0.2883,  0.0897, -0.1507, -0.9543,  0.5436,\n",
       "          0.6222,  0.5046, -0.5697,  0.9987,  1.0000,  0.9808,  0.8980,  0.9349,\n",
       "         -0.9985, -0.4482,  1.0000, -0.9661, -1.0000, -0.9542, -0.6938,  0.4319,\n",
       "         -1.0000, -0.2379, -0.0246, -0.9228,  0.3443,  0.9850,  0.9948, -1.0000,\n",
       "          0.8953,  0.9510, -0.6862,  0.8067, -0.4378,  0.9789,  0.5852,  0.5024,\n",
       "         -0.2596,  0.4328, -0.8178, -0.8846, -0.2905, -0.4308,  0.9896,  0.1864,\n",
       "         -0.7610, -0.9450,  0.2549, -0.0711, -0.1365, -0.9667, -0.2581,  0.1011,\n",
       "          0.7533,  0.2494,  0.3158, -0.7964,  0.3493, -0.1409,  0.5089,  0.6869,\n",
       "         -0.9515, -0.6474,  0.0360, -0.3830, -0.3485, -0.9730,  0.9754, -0.3848,\n",
       "          0.6628,  1.0000, -0.0087, -0.9131,  0.5264,  0.3125, -0.4841,  1.0000,\n",
       "          0.6818, -0.9859, -0.6103,  0.5725, -0.6014, -0.6513,  0.9996, -0.3671,\n",
       "         -0.3795, -0.1053,  0.9767, -0.9920,  0.9736, -0.9270, -0.9677,  0.9738,\n",
       "          0.9472, -0.4252, -0.7760,  0.1814, -0.6270,  0.2927, -0.9720,  0.6854,\n",
       "          0.4693, -0.1158,  0.9099, -0.8585, -0.6412,  0.4479, -0.3163,  0.2587,\n",
       "          0.8524,  0.5351, -0.3249,  0.1292, -0.3312, -0.5131, -0.9770,  0.3816,\n",
       "          1.0000, -0.0645,  0.3308, -0.3658, -0.1034, -0.1077,  0.5666,  0.6174,\n",
       "         -0.3477, -0.8874,  0.6503, -0.9616, -0.9892,  0.7945,  0.2682, -0.4106,\n",
       "          1.0000,  0.3956,  0.1933,  0.3204,  0.9090,  0.1034,  0.5987,  0.5239,\n",
       "          0.9811, -0.3257,  0.6082,  0.8859, -0.6895, -0.3712, -0.7476,  0.0281,\n",
       "         -0.9422, -0.0423, -0.9648,  0.9709,  0.6996,  0.4281,  0.2580,  0.4891,\n",
       "          1.0000, -0.0578,  0.7223, -0.3626,  0.8779, -0.9987, -0.8803, -0.4595,\n",
       "         -0.0476, -0.4521, -0.3870,  0.2959, -0.9713,  0.5178,  0.3467, -0.9914,\n",
       "         -0.9908,  0.0448,  0.7875,  0.0747, -0.9317, -0.6708, -0.6834,  0.4462,\n",
       "         -0.3378, -0.9348,  0.2421, -0.3892,  0.5024, -0.3239,  0.6160,  0.6520,\n",
       "          0.7156, -0.5690, -0.0455, -0.0861, -0.8239,  0.8271, -0.8681, -0.7140,\n",
       "         -0.2071,  1.0000, -0.6169,  0.7784,  0.7835,  0.7641, -0.2676,  0.2101,\n",
       "          0.8396,  0.2900, -0.5031, -0.5397, -0.6106, -0.4102,  0.7062,  0.1677,\n",
       "          0.5458,  0.8399,  0.6741,  0.1222, -0.0332,  0.1553,  0.9997, -0.1668,\n",
       "         -0.3320, -0.6500, -0.1554, -0.3909, -0.3687,  1.0000,  0.4113,  0.0450,\n",
       "         -0.9922, -0.6752, -0.9304,  1.0000,  0.8339, -0.8723,  0.7059,  0.4151,\n",
       "         -0.2317,  0.7837, -0.2420, -0.2846,  0.2281,  0.1536,  0.9602, -0.5767,\n",
       "         -0.9689, -0.6704,  0.4615, -0.9722,  0.9992, -0.6678, -0.3065, -0.4098,\n",
       "         -0.0170,  0.6443, -0.0132, -0.9838, -0.2517,  0.1423,  0.9755,  0.3089,\n",
       "         -0.6191, -0.9365,  0.4753,  0.5816, -0.6232, -0.9382,  0.9735, -0.9841,\n",
       "          0.5294,  1.0000,  0.4332, -0.4133,  0.2742, -0.5711,  0.3623,  0.0642,\n",
       "          0.6986, -0.9683, -0.4098, -0.2943,  0.3431, -0.2374,  0.0783,  0.6826,\n",
       "          0.2352, -0.5732, -0.6311, -0.2010,  0.4692,  0.8201, -0.2742, -0.2256,\n",
       "          0.1036, -0.2629, -0.9274, -0.3536, -0.5185, -0.9999,  0.7015, -1.0000,\n",
       "          0.2835, -0.0841, -0.2749,  0.8606,  0.5082,  0.5813, -0.7981, -0.5213,\n",
       "          0.6200,  0.8027, -0.3733, -0.0296, -0.7466,  0.3534, -0.1894,  0.2903,\n",
       "         -0.3926,  0.8201, -0.2972,  1.0000,  0.1686, -0.6492, -0.9806,  0.3240,\n",
       "         -0.3293,  1.0000, -0.9362, -0.9638,  0.3737, -0.7378, -0.8479,  0.4018,\n",
       "          0.1104, -0.7513, -0.8451,  0.9722,  0.8952, -0.6085,  0.4889, -0.3416,\n",
       "         -0.5611,  0.0550,  0.5768,  0.9888,  0.3977,  0.9371,  0.2786, -0.2664,\n",
       "          0.9779,  0.3496,  0.5900,  0.1366,  1.0000,  0.4202, -0.9476,  0.3095,\n",
       "         -0.9907, -0.2768, -0.9752,  0.3356,  0.3023,  0.9100, -0.3385,  0.9665,\n",
       "         -0.5003,  0.1233, -0.2930, -0.0246,  0.3892, -0.9255, -0.9894, -0.9849,\n",
       "          0.5432, -0.5232, -0.2076,  0.3217,  0.2343,  0.4647,  0.4603, -1.0000,\n",
       "          0.9471,  0.5064,  0.7345,  0.9651,  0.5094,  0.4627,  0.3008, -0.9890,\n",
       "         -0.9840, -0.4329, -0.4106,  0.7994,  0.6782,  0.9070,  0.4182, -0.5638,\n",
       "         -0.4694, -0.2698, -0.6503, -0.9937,  0.4690, -0.3664, -0.9733,  0.9656,\n",
       "         -0.1435, -0.1984,  0.2502, -0.5863,  0.9391,  0.8418,  0.4975,  0.1067,\n",
       "          0.6024,  0.9023,  0.9725,  0.9892, -0.6310,  0.8241, -0.2532,  0.5165,\n",
       "          0.5107, -0.9438,  0.2433,  0.3914, -0.3826,  0.3099, -0.2813, -0.9813,\n",
       "          0.4475, -0.3098,  0.5240, -0.4697,  0.0558, -0.4591, -0.2977, -0.8215,\n",
       "         -0.6650,  0.6812,  0.4795,  0.9166,  0.7202, -0.1606, -0.7206, -0.2321,\n",
       "         -0.5448, -0.9414,  0.9452, -0.0209, -0.1495,  0.5027,  0.0040,  0.7311,\n",
       "         -0.0918, -0.4266, -0.3062, -0.8243,  0.8984, -0.4192, -0.5862, -0.5356,\n",
       "          0.6628,  0.3908,  0.9998, -0.5771, -0.6544, -0.2762, -0.3847,  0.4352,\n",
       "         -0.4021, -1.0000,  0.4762, -0.2384,  0.5032, -0.3292,  0.5334, -0.3008,\n",
       "         -0.9849, -0.2677,  0.4999,  0.4842, -0.5571, -0.4787,  0.6036,  0.3051,\n",
       "          0.8739,  0.9051, -0.1019,  0.2896,  0.6685, -0.6048, -0.7155,  0.9298]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['pooler_output']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. from scratch\n",
    "![111](https://mccormickml.com/assets/BERT/padding_and_mask.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.9320, -0.4660, -0.7054,  0.8013,  0.5395, -0.2326,  0.8985,  0.3100,\n",
       "        -0.5941, -1.0000, -0.1055,  0.8209,  0.9858,  0.2604,  0.9526, -0.6847,\n",
       "        -0.2648, -0.6366,  0.3471, -0.7114,  0.6518,  0.9998,  0.4752,  0.3604,\n",
       "         0.5276,  0.9401, -0.6821,  0.9463,  0.9627,  0.7596, -0.7972,  0.2211,\n",
       "        -0.9909, -0.2564, -0.7488, -0.9928,  0.4347, -0.8085, -0.0717, -0.0137,\n",
       "        -0.9286,  0.3592,  1.0000, -0.4739,  0.2884, -0.4205, -1.0000,  0.3234,\n",
       "        -0.9190,  0.7232,  0.6715,  0.5167,  0.2301,  0.5236,  0.5461, -0.0622,\n",
       "        -0.0630,  0.1883, -0.2802, -0.6607, -0.6670,  0.3900, -0.6133, -0.9413,\n",
       "         0.5821,  0.5472, -0.1604, -0.3769, -0.1576, -0.0250,  0.9041,  0.2955,\n",
       "        -0.0418, -0.8321,  0.3900,  0.3109, -0.6546,  1.0000, -0.5625, -0.9819,\n",
       "         0.6171,  0.5162,  0.6011,  0.0482,  0.2289, -1.0000,  0.5958, -0.2103,\n",
       "        -0.9917,  0.1602,  0.5617, -0.2821,  0.4634,  0.6287, -0.4933, -0.3350,\n",
       "        -0.4028, -0.5878, -0.2872, -0.2631,  0.1988, -0.3540, -0.3882, -0.4115,\n",
       "         0.3234, -0.5114, -0.5085,  0.4941, -0.0114,  0.7357,  0.4615, -0.4198,\n",
       "         0.4495, -0.9632,  0.6444, -0.4120, -0.9886, -0.6143, -0.9883,  0.7400,\n",
       "        -0.0702, -0.2572,  0.9748, -0.0086,  0.3666, -0.1545, -0.7035, -1.0000,\n",
       "        -0.4364, -0.4116, -0.1010, -0.2736, -0.9826, -0.9627,  0.7004,  0.9718,\n",
       "         0.2619,  0.9998, -0.3054,  0.9478, -0.1006, -0.4293,  0.0960, -0.5103,\n",
       "         0.6878,  0.4061, -0.7764,  0.2234, -0.0699,  0.2507, -0.5001, -0.3151,\n",
       "        -0.6120, -0.9422, -0.4599,  0.9538, -0.2553, -0.7623,  0.4071, -0.2945,\n",
       "        -0.3870,  0.8860,  0.6171,  0.4231, -0.2888,  0.5307,  0.2569,  0.5667,\n",
       "        -0.9075,  0.2098,  0.5000, -0.3142, -0.6503, -0.9822, -0.3632,  0.5577,\n",
       "         0.9902,  0.7836,  0.4002,  0.6218, -0.4148,  0.5758, -0.9572,  0.9842,\n",
       "        -0.2230,  0.3169, -0.1974,  0.3705, -0.9103,  0.0049,  0.8592, -0.4281,\n",
       "        -0.8949, -0.1139, -0.5668, -0.4746, -0.5588,  0.5546, -0.4232, -0.4242,\n",
       "        -0.1781,  0.9459,  0.9806,  0.7665, -0.1614,  0.5974, -0.9268, -0.5548,\n",
       "         0.1379,  0.3220,  0.1891,  0.9944, -0.5132, -0.2329, -0.9579, -0.9876,\n",
       "        -0.0068, -0.9122, -0.1263, -0.7131,  0.5984,  0.0540,  0.3312,  0.4399,\n",
       "        -0.9913, -0.8647,  0.3815, -0.4357,  0.4890, -0.3445,  0.8146,  0.8397,\n",
       "        -0.7184,  0.7613,  0.9425, -0.6402, -0.7862,  0.8809, -0.3388,  0.9255,\n",
       "        -0.6946,  0.9935,  0.7557,  0.7025, -0.9382, -0.5615, -0.9338, -0.4925,\n",
       "        -0.2236, -0.1925,  0.7047,  0.6824,  0.4130,  0.5055, -0.6258,  0.9983,\n",
       "        -0.8016, -0.9645, -0.0566, -0.1498, -0.9907,  0.7389,  0.2659, -0.0726,\n",
       "        -0.5518, -0.6016, -0.9692,  0.9009,  0.1575,  0.9914, -0.2993, -0.9344,\n",
       "        -0.6036, -0.9323, -0.1166, -0.2883,  0.0897, -0.1507, -0.9543,  0.5436,\n",
       "         0.6222,  0.5046, -0.5697,  0.9987,  1.0000,  0.9808,  0.8980,  0.9349,\n",
       "        -0.9985, -0.4482,  1.0000, -0.9661, -1.0000, -0.9542, -0.6938,  0.4319,\n",
       "        -1.0000, -0.2379, -0.0246, -0.9228,  0.3443,  0.9850,  0.9948, -1.0000,\n",
       "         0.8953,  0.9510, -0.6862,  0.8067, -0.4378,  0.9789,  0.5852,  0.5024,\n",
       "        -0.2596,  0.4328, -0.8178, -0.8846, -0.2905, -0.4308,  0.9896,  0.1864,\n",
       "        -0.7610, -0.9450,  0.2549, -0.0711, -0.1365, -0.9667, -0.2581,  0.1011,\n",
       "         0.7533,  0.2494,  0.3158, -0.7964,  0.3493, -0.1409,  0.5089,  0.6869,\n",
       "        -0.9515, -0.6474,  0.0360, -0.3830, -0.3485, -0.9730,  0.9754, -0.3848,\n",
       "         0.6628,  1.0000, -0.0087, -0.9131,  0.5264,  0.3125, -0.4841,  1.0000,\n",
       "         0.6818, -0.9859, -0.6103,  0.5725, -0.6014, -0.6513,  0.9996, -0.3671,\n",
       "        -0.3795, -0.1053,  0.9767, -0.9920,  0.9736, -0.9270, -0.9677,  0.9738,\n",
       "         0.9472, -0.4252, -0.7760,  0.1814, -0.6270,  0.2927, -0.9720,  0.6854,\n",
       "         0.4693, -0.1158,  0.9099, -0.8585, -0.6412,  0.4479, -0.3163,  0.2587,\n",
       "         0.8524,  0.5351, -0.3249,  0.1292, -0.3312, -0.5131, -0.9770,  0.3816,\n",
       "         1.0000, -0.0645,  0.3308, -0.3658, -0.1034, -0.1077,  0.5666,  0.6174,\n",
       "        -0.3477, -0.8874,  0.6503, -0.9616, -0.9892,  0.7945,  0.2682, -0.4106,\n",
       "         1.0000,  0.3956,  0.1933,  0.3204,  0.9090,  0.1034,  0.5987,  0.5239,\n",
       "         0.9811, -0.3257,  0.6082,  0.8859, -0.6895, -0.3712, -0.7476,  0.0281,\n",
       "        -0.9422, -0.0423, -0.9648,  0.9709,  0.6996,  0.4281,  0.2580,  0.4891,\n",
       "         1.0000, -0.0578,  0.7223, -0.3626,  0.8779, -0.9987, -0.8803, -0.4595,\n",
       "        -0.0476, -0.4521, -0.3870,  0.2959, -0.9713,  0.5178,  0.3467, -0.9914,\n",
       "        -0.9908,  0.0448,  0.7875,  0.0747, -0.9317, -0.6708, -0.6834,  0.4462,\n",
       "        -0.3378, -0.9348,  0.2421, -0.3892,  0.5024, -0.3239,  0.6160,  0.6520,\n",
       "         0.7156, -0.5690, -0.0455, -0.0861, -0.8239,  0.8271, -0.8681, -0.7140,\n",
       "        -0.2071,  1.0000, -0.6169,  0.7784,  0.7835,  0.7641, -0.2676,  0.2101,\n",
       "         0.8396,  0.2900, -0.5031, -0.5397, -0.6106, -0.4102,  0.7062,  0.1677,\n",
       "         0.5458,  0.8399,  0.6741,  0.1222, -0.0332,  0.1553,  0.9997, -0.1668,\n",
       "        -0.3320, -0.6500, -0.1554, -0.3909, -0.3687,  1.0000,  0.4113,  0.0450,\n",
       "        -0.9922, -0.6752, -0.9304,  1.0000,  0.8339, -0.8723,  0.7059,  0.4151,\n",
       "        -0.2317,  0.7837, -0.2420, -0.2846,  0.2281,  0.1536,  0.9602, -0.5767,\n",
       "        -0.9689, -0.6704,  0.4615, -0.9722,  0.9992, -0.6678, -0.3065, -0.4098,\n",
       "        -0.0170,  0.6443, -0.0132, -0.9838, -0.2517,  0.1423,  0.9755,  0.3089,\n",
       "        -0.6191, -0.9365,  0.4753,  0.5816, -0.6232, -0.9382,  0.9735, -0.9841,\n",
       "         0.5294,  1.0000,  0.4332, -0.4133,  0.2742, -0.5711,  0.3623,  0.0642,\n",
       "         0.6986, -0.9683, -0.4098, -0.2943,  0.3431, -0.2374,  0.0783,  0.6826,\n",
       "         0.2352, -0.5732, -0.6311, -0.2010,  0.4692,  0.8201, -0.2742, -0.2256,\n",
       "         0.1036, -0.2629, -0.9274, -0.3536, -0.5185, -0.9999,  0.7015, -1.0000,\n",
       "         0.2835, -0.0841, -0.2749,  0.8606,  0.5082,  0.5813, -0.7981, -0.5213,\n",
       "         0.6200,  0.8027, -0.3733, -0.0296, -0.7466,  0.3534, -0.1894,  0.2903,\n",
       "        -0.3926,  0.8201, -0.2972,  1.0000,  0.1686, -0.6492, -0.9806,  0.3240,\n",
       "        -0.3293,  1.0000, -0.9362, -0.9638,  0.3737, -0.7378, -0.8479,  0.4018,\n",
       "         0.1104, -0.7513, -0.8451,  0.9722,  0.8952, -0.6085,  0.4889, -0.3416,\n",
       "        -0.5611,  0.0550,  0.5768,  0.9888,  0.3977,  0.9371,  0.2786, -0.2664,\n",
       "         0.9779,  0.3496,  0.5900,  0.1366,  1.0000,  0.4202, -0.9476,  0.3095,\n",
       "        -0.9907, -0.2768, -0.9752,  0.3356,  0.3023,  0.9100, -0.3385,  0.9665,\n",
       "        -0.5003,  0.1233, -0.2930, -0.0246,  0.3892, -0.9255, -0.9894, -0.9849,\n",
       "         0.5432, -0.5232, -0.2076,  0.3217,  0.2343,  0.4647,  0.4603, -1.0000,\n",
       "         0.9471,  0.5064,  0.7345,  0.9651,  0.5094,  0.4627,  0.3008, -0.9890,\n",
       "        -0.9840, -0.4329, -0.4106,  0.7994,  0.6782,  0.9070,  0.4182, -0.5638,\n",
       "        -0.4694, -0.2698, -0.6503, -0.9937,  0.4690, -0.3664, -0.9733,  0.9656,\n",
       "        -0.1435, -0.1984,  0.2502, -0.5863,  0.9391,  0.8418,  0.4975,  0.1067,\n",
       "         0.6024,  0.9023,  0.9725,  0.9892, -0.6310,  0.8241, -0.2532,  0.5165,\n",
       "         0.5107, -0.9438,  0.2433,  0.3914, -0.3826,  0.3099, -0.2813, -0.9813,\n",
       "         0.4475, -0.3098,  0.5240, -0.4697,  0.0558, -0.4591, -0.2977, -0.8215,\n",
       "        -0.6650,  0.6812,  0.4795,  0.9166,  0.7202, -0.1606, -0.7206, -0.2321,\n",
       "        -0.5448, -0.9414,  0.9452, -0.0209, -0.1495,  0.5027,  0.0040,  0.7311,\n",
       "        -0.0918, -0.4266, -0.3062, -0.8243,  0.8984, -0.4192, -0.5862, -0.5356,\n",
       "         0.6628,  0.3908,  0.9998, -0.5771, -0.6544, -0.2762, -0.3847,  0.4352,\n",
       "        -0.4021, -1.0000,  0.4762, -0.2384,  0.5032, -0.3292,  0.5334, -0.3008,\n",
       "        -0.9849, -0.2677,  0.4999,  0.4842, -0.5571, -0.4787,  0.6036,  0.3051,\n",
       "         0.8739,  0.9051, -0.1019,  0.2896,  0.6685, -0.6048, -0.7155,  0.9298],\n",
       "       grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_output = model.pooler.activation(\n",
    "    model.pooler.dense(outputs['last_hidden_state'][0][0,:]))\n",
    "my_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
