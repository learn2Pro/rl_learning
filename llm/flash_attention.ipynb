{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flash-attn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from flash_attn import flash_attn_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "batch_size=32\n",
    "seq_len=2048\n",
    "hidden_dim=1024\n",
    "\n",
    "\n",
    "Q = torch.randn(batch_size, seq_len, hidden_dim, dtype=torch.float16)\n",
    "K = torch.randn(batch_size, seq_len, hidden_dim, dtype=torch.float16)\n",
    "V = torch.randn(batch_size, seq_len, hidden_dim, dtype=torch.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-8.8916e-01, -7.9883e-01,  7.8467e-01,  ...,  6.1279e-01,\n",
       "          -1.1221e+00, -8.4277e-01],\n",
       "         [-1.2146e-01,  1.9736e+00,  2.7100e-01,  ..., -1.3896e+00,\n",
       "          -1.4270e-01,  7.4609e-01],\n",
       "         [-8.6084e-01, -5.4980e-01, -1.6055e+00,  ..., -6.3721e-01,\n",
       "           1.1953e+00, -1.2170e-01],\n",
       "         ...,\n",
       "         [-3.0664e-01, -5.7324e-01, -1.2581e-02,  ...,  5.5273e-01,\n",
       "           1.6484e+00,  5.4053e-01],\n",
       "         [ 1.1230e+00, -6.3184e-01, -4.1309e-01,  ...,  5.5322e-01,\n",
       "          -1.2578e+00, -5.3271e-01],\n",
       "         [-8.2568e-01, -3.1543e-01,  7.7539e-01,  ..., -1.4512e+00,\n",
       "           1.3730e+00, -7.9297e-01]],\n",
       "\n",
       "        [[ 1.4746e+00,  4.0527e-01, -1.3779e+00,  ...,  2.5610e-01,\n",
       "          -1.0430e+00,  8.1689e-01],\n",
       "         [-9.9060e-02,  1.0852e-01,  1.0586e+00,  ...,  1.0146e+00,\n",
       "           9.1699e-01,  6.9189e-01],\n",
       "         [-1.0537e+00,  7.6782e-02, -4.7827e-01,  ..., -1.8982e-01,\n",
       "          -3.8916e-01, -7.2266e-01],\n",
       "         ...,\n",
       "         [-3.1708e-02, -1.3955e+00,  4.1626e-01,  ..., -1.0394e-01,\n",
       "          -4.5215e-01, -2.3120e-01],\n",
       "         [ 7.2327e-02,  5.9277e-01, -9.7266e-01,  ..., -5.2344e-01,\n",
       "           6.4209e-01,  1.0901e-01],\n",
       "         [ 4.8706e-01, -1.3604e+00, -1.0156e+00,  ...,  3.0811e-01,\n",
       "          -6.2451e-01,  3.6682e-02]],\n",
       "\n",
       "        [[ 6.8750e-01, -7.9639e-01, -2.7271e-01,  ..., -1.1641e+00,\n",
       "           1.4111e+00,  1.8252e+00],\n",
       "         [ 1.9263e-01,  5.2295e-01, -8.1250e-01,  ...,  1.0693e+00,\n",
       "           6.4893e-01,  1.6387e+00],\n",
       "         [ 6.6553e-01,  3.3545e-01, -1.5596e+00,  ...,  2.7393e-01,\n",
       "           1.2061e+00,  8.9697e-01],\n",
       "         ...,\n",
       "         [ 7.4219e-01,  4.1992e-01, -1.4629e+00,  ..., -4.4824e-01,\n",
       "           1.3806e-01,  9.0576e-01],\n",
       "         [-5.0293e-01,  1.2793e+00,  1.6711e-01,  ..., -1.0596e+00,\n",
       "           1.8789e+00,  4.6338e-01],\n",
       "         [ 7.7930e-01, -1.1855e+00,  1.6931e-01,  ...,  6.1572e-01,\n",
       "           4.3872e-01,  4.1528e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.4570e+00, -1.8506e+00, -2.1899e-01,  ..., -1.0664e+00,\n",
       "          -2.3962e-01,  2.1797e+00],\n",
       "         [-1.4316e+00,  1.2578e+00,  6.1768e-01,  ...,  3.0249e-01,\n",
       "          -3.0430e+00, -3.9062e-01],\n",
       "         [-1.8965e+00,  8.4326e-01, -3.8940e-02,  ..., -2.0166e-01,\n",
       "          -6.5479e-01,  8.8730e-03],\n",
       "         ...,\n",
       "         [ 1.0724e-01,  4.3188e-01, -2.2227e+00,  ...,  8.9307e-01,\n",
       "          -1.7139e-01, -3.3643e-01],\n",
       "         [ 1.2285e+00, -1.9421e-01, -4.4751e-01,  ..., -1.3594e+00,\n",
       "           2.3008e+00, -1.6699e+00],\n",
       "         [ 5.4053e-01,  9.6338e-01,  1.0918e+00,  ..., -1.1631e+00,\n",
       "          -1.5479e+00, -5.7520e-01]],\n",
       "\n",
       "        [[ 3.0319e-02,  1.2080e+00, -1.9658e+00,  ..., -1.2822e+00,\n",
       "          -9.6680e-01,  2.9858e-01],\n",
       "         [ 7.5977e-01,  7.1680e-01,  1.4492e+00,  ...,  5.3613e-01,\n",
       "          -2.9770e-02,  2.9297e-01],\n",
       "         [ 1.1621e+00, -1.3096e+00,  5.9717e-01,  ..., -7.9053e-01,\n",
       "          -5.3223e-01, -7.4756e-01],\n",
       "         ...,\n",
       "         [ 8.7256e-01, -5.4639e-01, -2.0977e+00,  ..., -2.7481e-02,\n",
       "          -6.1523e-01, -1.8506e-01],\n",
       "         [-4.6661e-02,  4.5532e-01, -5.7959e-01,  ...,  1.5417e-01,\n",
       "           3.0103e-01,  6.1584e-02],\n",
       "         [-1.5615e+00, -1.1758e+00, -5.8838e-01,  ...,  8.2568e-01,\n",
       "           8.9014e-01, -9.9854e-01]],\n",
       "\n",
       "        [[ 5.1208e-02,  8.5449e-01, -1.1780e-01,  ..., -7.9443e-01,\n",
       "           8.1682e-04,  7.7979e-01],\n",
       "         [-8.2812e-01,  8.6865e-01,  5.3223e-01,  ...,  1.1904e+00,\n",
       "           7.8857e-01, -1.6445e+00],\n",
       "         [-9.4531e-01,  3.7061e-01, -2.0068e-01,  ...,  1.1113e+00,\n",
       "          -7.3535e-01, -9.6069e-02],\n",
       "         ...,\n",
       "         [-1.2324e+00, -8.4717e-01, -1.3047e+00,  ...,  2.3867e+00,\n",
       "           1.2920e+00,  2.1069e-01],\n",
       "         [ 2.4927e-01,  1.5361e+00, -7.2363e-01,  ..., -1.6895e+00,\n",
       "           4.8340e-02, -1.8613e+00],\n",
       "         [-2.0142e-01, -4.2139e-01,  1.5137e+00,  ...,  7.9541e-01,\n",
       "           2.3645e-01, -2.7383e+00]]], dtype=torch.float16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (1024) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax((\u001b[43mQ\u001b[49m\u001b[38;5;129;43m@K\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m32\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m output \u001b[38;5;241m=\u001b[39m attn_weights\u001b[38;5;129m@V\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (1024) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "## attention\n",
    "def attention(q, k, v, mask=None, dropout=None):\n",
    "    d_k = q.size(-1)\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, v), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
